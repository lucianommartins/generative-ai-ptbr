{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ijGzTHJJUCPY"
   },
   "outputs": [],
   "source": [
    "# Copyright 2023 Google LLC\n",
    "#\n",
    "# Licensed under the Apache License, Version 2.0 (the \"License\");\n",
    "# you may not use this file except in compliance with the License.\n",
    "# You may obtain a copy of the License at\n",
    "#\n",
    "#     https://www.apache.org/licenses/LICENSE-2.0\n",
    "#\n",
    "# Unless required by applicable law or agreed to in writing, software\n",
    "# distributed under the License is distributed on an \"AS IS\" BASIS,\n",
    "# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
    "# See the License for the specific language governing permissions and\n",
    "# limitations under the License."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "VEqbX8OhE8y9"
   },
   "source": [
    "# Retrieval Augmented Generation (RAG) multimodal usando a Vertex AI Gemini API\n",
    "\n",
    "<table align=\"left\">\n",
    "  <td style=\"text-align: center\">\n",
    "    <a href=\"https://colab.research.google.com/github/GoogleCloudPlatform/generative-ai/blob/main/gemini/use-cases/retrieval-augmented-generation/intro_multimodal_rag.ipynb\">\n",
    "      <img src=\"https://cloud.google.com/ml-engine/images/colab-logo-32px.png\" alt=\"Google Colaboratory logo\"><br> Execute no Colab\n",
    "    </a>\n",
    "  </td>\n",
    "  <td style=\"text-align: center\">\n",
    "    <a href=\"https://github.com/GoogleCloudPlatform/generative-ai/blob/main/gemini/use-cases/retrieval-augmented-generation/intro_multimodal_rag.ipynb\">\n",
    "      <img src=\"https://cloud.google.com/ml-engine/images/github-logo-32px.png\" alt=\"GitHub logo\"><br> Veja no GitHub\n",
    "    </a>\n",
    "  </td>\n",
    "  <td style=\"text-align: center\">\n",
    "    <a href=\"https://console.cloud.google.com/vertex-ai/workbench/deploy-notebook?download_url=https://raw.githubusercontent.com/GoogleCloudPlatform/generative-ai/blob/main/gemini/use-cases/retrieval-augmented-generation/intro_multimodal_rag.ipynb\">\n",
    "      <img src=\"https://lh3.googleusercontent.com/UiNooY4LUgW_oTvpsNhPpQzsstV5W8F7rYgxgGBD85cWJoLmrOzhVs_ksK_vgx40SHs7jCqkTkCk=e14-rj-sc0xffffff-h130-w32\" alt=\"Vertex AI logo\"><br> Abra no Workbench da Vertex AI\n",
    "    </a>\n",
    "  </td>\n",
    "</table>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "VK1Q5ZYdVL4Y"
   },
   "source": [
    "## Visão geral\n",
    "\n",
    "A geração aumentada de recuperação (RAG) é uma abordagem popular para permitir que LLMs acessem dados externos e também como um mecanismo de *groundin* para mitigar alucinações.\n",
    "\n",
    "Neste notebook, você aprenderá como realizar RAG multimodal, onde realizará perguntas e respostas sobre um documento financeiro preenchido com texto e imagens.\n",
    "\n",
    "### Gemini\n",
    "\n",
    "Gemini é uma família de modelos generativos de IA desenvolvidos pelo Google DeepMind e projetados para casos de uso multimodais. A API Gemini dá acesso aos modelos `Gemini Pro Vision` e `Gemini Pro`.\n",
    "\n",
    "### Comparando RAG baseado em texto e multimodal\n",
    "\n",
    "O RAG multimodal oferece diversas vantagens sobre o RAG baseado em texto:\n",
    "\n",
    "1. **Acesso aprimorado ao conhecimento:** O RAG multimodal pode acessar e processar informações textuais e visuais, fornecendo uma base de conhecimento mais rica e abrangente para o LLM.\n",
    "2. **Capacidades de raciocínio aprimoradas:** Ao incorporar dicas visuais, o RAG multimodal pode fazer inferências mais bem informadas em diferentes tipos de modalidades de dados.\n",
    "\n",
    "Este notebook mostra como usar o RAG com a API Vertex AI Gemini, [embeddings de texto](https://cloud.google.com/vertex-ai/docs/generative-ai/model-reference/text-embeddings) e [ embeddings multimodais](https://cloud.google.com/vertex-ai/docs/generative-ai/model-reference/multimodal-embeddings), para criar um mecanismo de pesquisa de documentos.\n",
    "\n",
    "Através de exemplos práticos, você descobrirá como construir um repositório de metadados rico em multimídia de suas fontes de documentos, permitindo pesquisa, comparação e raciocínio em diversos fluxos de informações."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "RQT500QqVPIb"
   },
   "source": [
    "### Objetivos\n",
    "\n",
    "Este notebook fornece um guia para construir um mecanismo de busca de documentos usando geração aumentada de recuperação multimodal (RAG), passo a passo:\n",
    "\n",
    "1. Extraia e armazene metadados de documentos contendo texto e imagens e gere incorporações nos documentos\n",
    "2. Pesquise os metadados com consultas de texto para encontrar textos ou imagens semelhantes\n",
    "3. Pesquise os metadados com consultas de imagens para encontrar imagens semelhantes\n",
    "4. Usando uma consulta de texto como entrada, pesquise respostas contextuais usando texto e imagens"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Custos\n",
    "\n",
    "Este tutorial usa os seguintes componentes de Google Cloud que podem gerar custos em sua fatura:\n",
    "\n",
    "- Vertex AI\n",
    "\n",
    "Saiba mais sobre [preços da Vertex AI](https://cloud.google.com/vertex-ai/pricing) e use a [calculadora de preços](https://cloud.google.com/products/calculator/) para gerar uma estimativa de custo com base no uso projetado."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Primeiros passos"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "N5afkyDMSBW5"
   },
   "source": [
    "### Instale a SDK da Vertex AI\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "kc4WxYmLSBW5",
    "outputId": "64a92007-dee1-4629-bee6-a3fa43d79b47",
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "! pip3 install --upgrade --user google-cloud-aiplatform pymupdf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "j7UyNVSiyQ96"
   },
   "source": [
    "### **Somente para uso no Colab - Reinicie o kernel do notebook** \n",
    "\n",
    "Caso você esteja executando este notebook no Google Colab, descomente a célula abaixo para realizar o restart do kernel do notebook (etapa importante para que o Colab reconheça a nova versão da SDK) e a execute. Senão, siga para as próximas instruções."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "YmY9HVVGSBW5",
    "outputId": "508067b0-486c-445b-fad5-6480f495eba0",
    "tags": []
   },
   "outputs": [],
   "source": [
    "# import IPython\n",
    "\n",
    "# app = IPython.Application.instance()\n",
    "# app.kernel.do_shutdown(True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Somente para uso no Colab - Autentique o seu ambiente de notebook** \n",
    "\n",
    "Caso você esteja executando este notebook no Google Colab, descomente a célula abaixo para realizar a autenticação da sua sessão de notebook com a Google Cloud Esse passo é importante **para utilização no Colab** para garantir que as chamadas a APIs de Google Cloud funcionem sem problemas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# import sys\n",
    "\n",
    "# # Additional authentication is required for Google Colab\n",
    "# if \"google.colab\" in sys.modules:\n",
    "#     # Authenticate user to Google Cloud\n",
    "#     from google.colab import auth\n",
    "\n",
    "#     auth.authenticate_user()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Somente para uso no Colab - defina o projeto Google Cloud a ser utilizado** \n",
    "\n",
    "Caso você esteja executando este notebook no Google Colab, descomente a célula abaixo para definir qual projeto Google Cloud será utilizado pelo Colab na execução deste notebook. Senão, siga para as próximas instruções."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# if \"google.colab\" in sys.modules:\n",
    "#     # Define project information\n",
    "#     PROJECT_ID = \"[your-project-id]\"  # @param {type:\"string\"}\n",
    "#     LOCATION = \"us-central1\"  # @param {type:\"string\"}\n",
    "\n",
    "#     # Initialize Vertex AI\n",
    "#     import vertexai\n",
    "\n",
    "#     vertexai.init(project=PROJECT_ID, location=LOCATION)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "BuQwwRiniVFG"
   },
   "source": [
    "### Importe as bibliotecas necessárias"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "rtMowvm-yQ97",
    "tags": []
   },
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '3' \n",
    "\n",
    "import warnings\n",
    "warnings.simplefilter(\"ignore\", UserWarning)\n",
    "\n",
    "from IPython.display import Markdown, display\n",
    "from vertexai.preview.generative_models import (\n",
    "    Content,\n",
    "    GenerationConfig,\n",
    "    GenerationResponse,\n",
    "    GenerativeModel,\n",
    "    Image,\n",
    "    Part,\n",
    ")\n",
    "\n",
    "PROJECT_ID = \"lucianomartins-demos-345000\"  # @param {type:\"string\"}\n",
    "LOCATION = \"us-central1\"  # @param {type:\"string\"}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Importe o modelo `Gemini Pro`\n",
    "\n",
    "O Gemini Pro (`gemini-pro`) ajuda na realização de tarefas utilizando linguagem natural, chats multiturno de texto e código e para a geração de código."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "model = GenerativeModel(\"gemini-pro-vision\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "1lCfREXK5SWD"
   },
   "source": [
    "### Baixe módulos e utilitários Python customizados\n",
    "\n",
    "A célula abaixo fará o download de algumas funções auxiliares necessárias para este notebook. Você também pode visualizar o código (`intro_multimodal_rag_utils.py`) diretamente no [Github](https://raw.githubusercontent.com/GoogleCloudPlatform/generative-ai/main/gemini/use-cases/retrieval-augmented-generation/utils/intro_multimodal_rag_utils.py)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "XhiFT91850ZZ",
    "tags": []
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import urllib.request\n",
    "import sys\n",
    "\n",
    "if not os.path.exists(\"utils\"):\n",
    "    os.makedirs(\"utils\")\n",
    "\n",
    "    \n",
    "# download the helper scripts from utils folder\n",
    "url_prefix = \"https://raw.githubusercontent.com/GoogleCloudPlatform/generative-ai/main/gemini/use-cases/retrieval-augmented-generation/utils/\"\n",
    "files = [\"intro_multimodal_rag_utils.py\"]\n",
    "\n",
    "for fname in files:\n",
    "    urllib.request.urlretrieve(f\"{url_prefix}/{fname}\", filename=f\"utils/{fname}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "g7bKCQMFT7JT"
   },
   "source": [
    "#### Baixe documentos e imagens do Cloud Storage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "KwbL89zcY39N",
    "outputId": "86c49e32-915b-47f6-9221-fcb9e87eb941",
    "tags": []
   },
   "outputs": [],
   "source": [
    "# download documents and images used in this notebook\n",
    "!gsutil -m rsync -r gs://github-repo/rag/intro_multimodal_rag .\n",
    "print(\"Download finalizado.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Ps1G-cCfpibN"
   },
   "source": [
    "## Construa os metadados dos documentos (contendo texto e imagem)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "jqLsy3iZ5t-R"
   },
   "source": [
    "### Os dados\n",
    "\n",
    "Os dados que você usará neste notebook são uma versão modificada do [Google-10K](https://abc.xyz/assets/investor/static/pdf/20220202_alphabet_10K.pdf) que fornece uma visão geral abrangente da situação financeira da Alphabet, como desempenho, operações de negócios, gerenciamento e fatores de risco. Como o documento original é bastante grande, você usará [uma versão modificada com apenas 14 páginas](https://storage.googleapis.com/github-repo/rag/intro_multimodal_rag/google-10k-sample-14pages.pdf). Embora esteja truncado, o documento de amostra ainda contém texto junto com imagens como tabelas, tabelas e gráficos."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "zvt0sus5KSNX"
   },
   "source": [
    "### Importe funções auxiliares para construir metadados\n",
    "\n",
    "Antes de construir o sistema RAG multimodal, é importante ter metadados de todos os textos e imagens do documento. Para fins de referências e citações, os metadados devem conter elementos essenciais, incluindo número de página, nome do arquivo, contador de imagens e assim por diante. Portanto, como próxima etapa, você gerará embeddings a partir dos metadados, que serão necessários para realizar a pesquisa de similaridade ao consultar os dados."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Mf9etD854ckM",
    "tags": []
   },
   "outputs": [],
   "source": [
    "from utils.intro_multimodal_rag_utils import get_document_metadata"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "5BOAkYN0KlSL"
   },
   "source": [
    "### Extraia e armazene metadados de texto e imagens de um documento"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Q9hBPPWs5CMd"
   },
   "source": [
    "Você acabou de importar uma função chamada `get_document_metadata()`. Esta função extrai metadados de texto e imagem de um documento e retorna dois dataframes, *text_metadata* e *image_metadata*, como saídas. Se você quiser saber mais sobre como a função `get_document_metadata()` é implementada usando Gemini e os modelos de *embeddings*, você pode dar uma olhada no [código-fonte](https://raw.githubusercontent.com/GoogleCloudPlatform/generative-ai/main/gemini/use-cases/retrieval-augmented-generation/utils/intro_multimodal_rag_utils.py) diretamente.\n",
    "\n",
    "A razão para extrair e armazenar metadados de texto e metadados de imagem é que apenas usar um dos dois não é suficiente para obter uma resposta relevante. Por exemplo, as respostas relevantes poderiam estar em formato visual dentro de um documento, mas o RAG baseado em texto não poderá levar em consideração as imagens visuais. Você também explorará esse exemplo posteriormente neste notebook."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Na próxima etapa, você usará a função para extrair e armazenar metadados de texto e imagens de um documento. Observe que a célula a seguir pode levar alguns minutos para ser concluída:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "X8hE0tWD-lf8",
    "outputId": "cc91faed-7a94-4ff2-fc8e-68f9fed696e0",
    "tags": []
   },
   "outputs": [],
   "source": [
    "pdf_path = \"google-10k-sample-14pages.pdf\"\n",
    "\n",
    "image_description_prompt = \"\"\"Explique a imagem.\n",
    "Não inclua números que não sejam mencionados na imagem:\"\"\"\n",
    "\n",
    "# Se for uma tabela, extraia os elementos da tabela.\n",
    "# Se for um gráfico, explique as descobertas no gráfico.\n",
    "\n",
    "text_metadata_df, image_metadata_df = get_document_metadata(\n",
    "    PROJECT_ID,\n",
    "    model,\n",
    "    pdf_path,\n",
    "    image_save_dir=\"images\",\n",
    "    image_description_prompt=image_description_prompt,\n",
    "    embedding_size=1408,\n",
    "    text_emb_text_limit=1000,\n",
    ")\n",
    "\n",
    "print(\"--- Processamento finalizado. ---\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Inspecione os metadados de texto processados\n",
    "\n",
    "A célula a seguir produzirá uma tabela de metadados que descreve as diferentes partes dos metadados de texto, incluindo:\n",
    "\n",
    "- **text**: o texto original da página\n",
    "- **text_embedding_page**: o *embedding* do texto original da página\n",
    "- **chunk_text**: o texto original dividido em pedaços menores\n",
    "- **chuck_number**: o índice de cada pedaço de texto\n",
    "- **text_embedding_chunk**: a *embedding* de cada pedaço de texto"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 293
    },
    "id": "6t3AIGFar8Mo",
    "outputId": "728ab634-e87e-4f5b-ddb3-c5ce796d1e1c",
    "tags": []
   },
   "outputs": [],
   "source": [
    "text_metadata_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Inspecione os metadados das imagens processadas\n",
    "\n",
    "A célula a seguir produzirá uma tabela de metadados que descreve as diferentes partes dos metadados da imagem, incluindo:\n",
    "* **img_desc**: descrição textual da imagem gerada pelo Gemini.\n",
    "* **mm_embedding_from_text_desc_and_img**: Embedding combinada de imagem e sua descrição, capturando informações visuais e textuais.\n",
    "* **mm_embedding_from_img_only**: Embedding de imagem sem descrição, para comparação com análise baseada em descrição.\n",
    "* **text_embedding_from_image_description**: Embedding de texto separada da descrição gerada, permitindo análise e comparação textual."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 590
    },
    "id": "tkHtAYIK-y-q",
    "outputId": "cb454e6a-1dbe-4d07-c392-6b6a7d59d9cb",
    "tags": []
   },
   "outputs": [],
   "source": [
    "image_metadata_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "iBhoOkutUtPr"
   },
   "source": [
    "### Importe as funções auxiliares para implementar o RAG\n",
    "\n",
    "Você importará as seguintes funções que serão usadas no restante deste notebook para implementar o RAG:\n",
    "\n",
    "* **get_similar_text_from_query():** Dada uma consulta de texto, encontra textos do documento que são relevantes, usando o algoritmo de similaridade de cosseno. Ele usa incorporações de texto dos metadados para calcular e os resultados podem ser filtrados por pontuação máxima, número de página/bloco ou tamanho de incorporação.\n",
    "* **print_text_to_text_citation():** Cite a fonte (citação) e detalhes do texto recuperado da função `get_similar_text_from_query()`.\n",
    "* **get_similar_image_from_query():** Dado um caminho de imagem ou uma imagem, encontra imagens do documento que são relevantes. Ele usa incorporações de imagens dos metadados.\n",
    "* **print_text_to_image_citation():** Cite a fonte (citação) e os detalhes das imagens recuperadas da função `get_similar_image_from_query()`.\n",
    "* **get_gemini_response():** Interage com um modelo Gemini para responder perguntas com base em uma combinação de entradas de texto e imagem."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Tngn_vrIKdE1",
    "tags": []
   },
   "outputs": [],
   "source": [
    "from utils.intro_multimodal_rag_utils import (\n",
    "    get_similar_text_from_query,\n",
    "    print_text_to_text_citation,\n",
    "    get_similar_image_from_query,\n",
    "    print_text_to_image_citation,\n",
    "    get_gemini_response,\n",
    "    display_images,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "c9jGEj6DY1Rj"
   },
   "source": [
    "Antes de implementar um RAG multimodal, vamos dar um passo atrás e explorar o que você pode conseguir apenas com embeddings de texto ou imagem. Isso ajudará a estabelecer as bases para a implementação de um RAG multimodal, o que você fará na parte posterior do notebook. Você também pode usar esses elementos essenciais juntos para criar aplicativos para casos de uso multimodais para extrair informações significativas de documentos."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "KHuLlEvSKFWt"
   },
   "source": [
    "## Busca textual\n",
    "\n",
    "Vamos começar a pesquisa com uma pergunta simples e ver se a pesquisa de texto simples usando incorporações de texto pode respondê-la. A resposta esperada é mostrar o valor do lucro líquido básico e diluído por ação do Google para diferentes tipos de ações."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "5mrFVhtCut7t",
    "tags": []
   },
   "outputs": [],
   "source": [
    "query = \"Preciso de detalhes sobre o lucro líquido básico e diluído por ação Classe A, Classe B e Classe C do Google?\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "XWw7-AIar-S8"
   },
   "source": [
    "### Search similar text with text query"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "eEzP6Yyv7N-G",
    "outputId": "dc66eaea-3707-42e4-9c83-ebd1e07da3ad",
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Matching user text query with \"chunk_embedding\" to find relevant chunks.\n",
    "matching_results_text = get_similar_text_from_query(\n",
    "    PROJECT_ID,\n",
    "    query,\n",
    "    text_metadata_df,\n",
    "    column_name=\"text_embedding_chunk\",\n",
    "    top_n=3,\n",
    "    embedding_size=1408,\n",
    "    chunk_text=True,\n",
    ")\n",
    "\n",
    "# Print the matched text citations\n",
    "print_text_to_text_citation(matching_results_text, print_top=True, chunk_text=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "v8ux39zFqyLh"
   },
   "source": [
    "Embora a resposta tenha sido devolvida, ela não retornou o valor relevante, que é o lucro líquido básico e diluído por ação. Isso ocorre porque as informações estão disponíveis apenas nas imagens e não na parte do texto do documento. Este é um dos exemplos de uma pesquisa de texto padrão (incluindo RAG de texto) que não retorna informações relevantes, embora as informações estejam presentes no documento."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "2itkRuikq_g6"
   },
   "source": [
    "**Importante:** criamos exemplos artesanais em nosso documento para simular casos do mundo real em que as informações geralmente estão incorporadas em gráficos, tabelas, gráficos e outros elementos baseados em imagens e não estão disponíveis como texto simples."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "uXm271jdD-Rl"
   },
   "source": [
    "### Busque imagens a partir de buscas textuais"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "oPxwfyVrr9-G"
   },
   "source": [
    "Como a pesquisa de texto simples não forneceu a resposta desejada e as informações podem ser representadas visualmente em uma tabela ou outro formato de imagem, você usará o recurso multimodal do modelo `Gemini Pro Vision`. O objetivo aqui também é encontrar uma imagem semelhante à consulta de texto. Você também pode listar as citações para verificar."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 491
    },
    "id": "knj4qQ4xni24",
    "outputId": "4742a790-9757-4317-b961-42dc458d7398",
    "tags": []
   },
   "outputs": [],
   "source": [
    "matching_results_image = get_similar_image_from_query(\n",
    "    PROJECT_ID,\n",
    "    text_metadata_df,\n",
    "    image_metadata_df,\n",
    "    query=query,\n",
    "    column_name=\"text_embedding_from_image_description\",  # Use image description text embedding\n",
    "    image_emb=False,  # Use text embedding instead of image embedding\n",
    "    top_n=3,\n",
    "    embedding_size=1408,\n",
    ")\n",
    "\n",
    "# Markdown(print_text_to_image_citation(matching_results_image, print_top=True))\n",
    "print(\"\\n **** Resultado: ***** \\n\")\n",
    "\n",
    "# Display the top matching image\n",
    "display(matching_results_image[0][\"image_object\"])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "SnFdFkWEtYrF"
   },
   "source": [
    "A busca encontrou exatamente o que você procurava. Você queria os detalhes sobre o lucro líquido básico e diluído das ações Classe A, B e C do Google. Esta imagem se encaixa perfeitamente graças aos seus metadados descritivos usando Gemini.\n",
    "\n",
    "Você também pode ver a citação e verificar o que Gemini extraiu como descrição para o resultado principal."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "8ScxlIywuqRe",
    "outputId": "179a2bdd-7faa-4b7c-cd1c-ec9646baa849",
    "tags": []
   },
   "outputs": [],
   "source": [
    "## you can check the citations to probe further.\n",
    "## check the \"image description:\" which is a description extracted through gemini which helped search our query.\n",
    "Markdown(print_text_to_image_citation(matching_results_image, print_top=True))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "oDd9rE4NrRod"
   },
   "source": [
    "## Busca por imagem"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "pJL6ElyEy4mc"
   },
   "source": [
    "### Similaridade de imagens utilizando a busca por imagem"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ReKjHleFxUu9"
   },
   "source": [
    "Imagine pesquisar imagens, mas em vez de digitar palavras, você usa uma imagem real como pista. Você tem uma tabela com números sobre o custo da receita de dois anos e deseja encontrar outras imagens semelhantes, no mesmo documento ou em vários documentos.\n",
    "\n",
    "Pense nisso como pesquisar com um minimapa em vez de um endereço escrito. É uma maneira diferente de perguntar: “Mostre-me mais coisas como esta”. Então, em vez de digitar “tabela de custo de receita 2020 2021”, você mostra uma imagem dessa tabela e diz: “Encontre-me mais como isto”\n",
    "\n",
    "Para fins de demonstração, encontraremos apenas imagens semelhantes que mostram o custo da receita ou valores semelhantes em um único documento abaixo. No entanto, você pode dimensionar esse padrão de design para corresponder (encontrar imagens relevantes) em vários documentos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 157
    },
    "id": "DJhhS5eZw7QI",
    "outputId": "850df709-8322-4ef4-862a-638cfb02f026",
    "tags": []
   },
   "outputs": [],
   "source": [
    "# You can find a similar image as per the images you have in the metadata.\n",
    "# In this case, you have a table (picked from the same document source) and you would like to find similar tables in the document.\n",
    "image_query_path = \"tac_table_revenue.png\"\n",
    "\n",
    "# Print a message indicating the input image\n",
    "print(\"***Imagem enviada pelo usuário:***\")\n",
    "\n",
    "# Display the input image\n",
    "Image.load_from_file(image_query_path)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "3zBTtGChTmrd"
   },
   "source": [
    "Você espera encontrar tabelas (como imagens) semelhantes em termos de \"Other/Total cost of revenues\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 419
    },
    "id": "nZcU7vZC-8vr",
    "outputId": "d01a1bc9-95ea-4daa-9df0-5abd79310381",
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Search for Similar Images Based on Input Image and Image Embedding\n",
    "\n",
    "matching_results_image = get_similar_image_from_query(\n",
    "    PROJECT_ID,\n",
    "    text_metadata_df,\n",
    "    image_metadata_df,\n",
    "    query=query,  # Use query text for additional filtering (optional)\n",
    "    column_name=\"mm_embedding_from_img_only\",  # Use image embedding for similarity calculation\n",
    "    image_emb=True,\n",
    "    image_query_path=image_query_path,  # Use input image for similarity calculation\n",
    "    top_n=3,  # Retrieve top 3 matching images\n",
    "    embedding_size=1408,  # Use embedding size of 1408\n",
    ")\n",
    "\n",
    "print(\"\\n **** Resultado: ***** \\n\")\n",
    "\n",
    "# Display the Top Matching Image\n",
    "display(\n",
    "    matching_results_image[0][\"image_object\"]\n",
    ")  # Display the top matching image object (Pillow Image)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "uhT17rke15XY"
   },
   "source": [
    "O modelo encontrou uma imagem (tabela) de aparência semelhante, que fornece mais detalhes sobre diferentes receitas, despesas, receitas e mais alguns detalhes com base na imagem fornecida. Mais importante ainda, ambas as tabelas mostram números relacionados ao “custo da receita”.\n",
    "\n",
    "Você também pode listar a citação para ver o que ela corresponde."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "mksXQoezweg0",
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Display citation details for the top matching image\n",
    "print_text_to_image_citation(matching_results_image, print_top=True)  # Print citation details for the top matching image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "VJWnhDJwI-uO",
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Check Other Matched Images (Optional)\n",
    "# You can access the other two matched images using:\n",
    "\n",
    "print(\"---------------Imagens encontradas------------------\\n\")\n",
    "display_images(\n",
    "    [\n",
    "        matching_results_image[0][\"img_path\"],\n",
    "        matching_results_image[1][\"img_path\"],\n",
    "    ],\n",
    "    resize_ratio = 0.8\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "JvwZIgD84CNc"
   },
   "source": [
    "A capacidade de identificar textos e imagens semelhantes com base na entrada do usuário, alimentada pelo Gemini e embeddings, constitui uma base crucial para o desenvolvimento de sistemas RAG multimodais, que você explorará na próxima seção."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "lUnsv5Co6pJF"
   },
   "source": [
    "### *Reasoning* comparativo"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "1AFbqHiz5vvo"
   },
   "source": [
    "Imagine que você tem um gráfico que mostra o desempenho das ações Classe A do Google em comparação com outras coisas, como o S&P 500 ou outras empresas de tecnologia. Você quer saber o desempenho das ações da Classe C em comparação com esse gráfico. Em vez de apenas encontrar outra imagem semelhante, você pode pedir o Gemini para comparar as imagens relevantes e dizer em qual ação seria melhor para você investir. Gemini então explicaria o *reasoning* da sugestão.\n",
    "\n",
    "O objetivo é enviar uma imagem de referência (ações Classe A do Google) e fazer perguntas simples de raciocínio como “Como isso se compara às ações Classe C?”. Você espera que os embeddings de imagens encontrem a imagem dos compartilhamentos Classe C e, em seguida, enviem a imagem de referência (compartilhamento Classe A) e a imagem semelhante (compartilhamento Classe C) para o Gemini e façam um raciocínio comparativo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 440
    },
    "id": "s2lk3sL60VVt",
    "outputId": "6b1a65e5-8903-4cf0-ff12-6e513bc6b959",
    "tags": []
   },
   "outputs": [],
   "source": [
    "image_query_path = \"class_a_share.png\"\n",
    "\n",
    "# Print a message indicating the input image\n",
    "print(\"***Imagem enviada pelo usuário:***\")\n",
    "\n",
    "# Display the input image\n",
    "Image.load_from_file(image_query_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 46
    },
    "id": "Pwu0vdoGAggb",
    "outputId": "66af23dd-2abb-43ef-9222-38e1cfa4826f",
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Load the input image using Pillow\n",
    "user_image_object = Image.load_from_file(image_query_path)\n",
    "\n",
    "# Define the comparison query\n",
    "compare_query = \"\"\"Pergunta: Quem performou melhor? NASDAQ Composite ou ações Classe A do Google?\n",
    "Resposta: \"\"\"\n",
    "instructions = \"\"\"instruções: Compare duas imagens e baseie seu raciocínio apenas nas imagens fornecidas.\n",
    "Forneça um raciocínio detalhado de suas conclusões.\n",
    "Imagens: \"\"\"\n",
    "\n",
    "# Find similar images based on the input image\n",
    "image_selected_based_on_source_image = get_similar_image_from_query(\n",
    "    PROJECT_ID,\n",
    "    text_metadata_df,\n",
    "    image_metadata_df,\n",
    "    image_query_path=image_query_path,\n",
    "    column_name=\"mm_embedding_from_img_only\",\n",
    "    image_emb=True,\n",
    "    top_n=3,\n",
    "    embedding_size=1408,\n",
    ")\n",
    "\n",
    "# Select the best matching image from the search results\n",
    "selected_image_object = image_selected_based_on_source_image[0][\"image_object\"]\n",
    "\n",
    "# Prepare the model input\n",
    "model_input = [instructions, user_image_object, selected_image_object, compare_query]\n",
    "\n",
    "# Generate Gemini response with streaming output\n",
    "Markdown(get_gemini_response(model, model_input=model_input, stream=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 668
    },
    "id": "KNTe9sLE2SfV",
    "outputId": "178fbf5e-e1f3-4f15-f0e5-3f782f7b1abf",
    "tags": []
   },
   "outputs": [],
   "source": [
    "# image selected by the model to make the comparision based on user query\n",
    "Image.load_from_file(image_selected_based_on_source_image[0][\"img_path\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Ih_2Dst06ITn"
   },
   "source": [
    "O Gemini não apenas encontrou a imagem compartilhada do Google Classe C, mas também fez um raciocínio comparativo e forneceu uma resposta contextual à consulta do usuário com o raciocínio adequado. Você também pode tornar o raciocínio mais fundamentado passando as descrições das imagens e o texto da página (texto disponível ao redor dos gráficos) para que haja menos chances de alucinação."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "bWcWohjir97J",
    "outputId": "a660438b-35b7-4dc8-e0fc-d7355a22e2ad",
    "tags": []
   },
   "outputs": [],
   "source": [
    "# citations\n",
    "print_text_to_image_citation(image_selected_based_on_source_image, print_top=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "7dhazjyNLSGT"
   },
   "source": [
    "\n",
    "<div class=\"alert alert-block alert-warning\">\n",
    "<b>⚠️ IMPORTANTE: Este não é um verdadeiro conselho de investimento e não deve ser levado a sério!! ⚠️</b>\n",
    "</div>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "efJPPrzRhvIT"
   },
   "source": [
    "## RAG multimodal\n",
    "\n",
    "Vamos juntar tudo para implementar o RAG multimodal. Você usará todos os elementos explorados nas seções anteriores para implementar o RAG multimodal. Estas são as etapas:\n",
    "\n",
    "* **Etapa 1:** O usuário faz uma consulta em formato de texto onde as informações esperadas estão disponíveis no documento e incorporadas em imagens e texto.\n",
    "* **Etapa 2:** Encontre todos os trechos de texto das páginas dos documentos usando um método semelhante ao que você explorou em `Pesquisa de texto`.\n",
    "* **Etapa 3:** Encontre todas as imagens semelhantes nas páginas com base na consulta do usuário correspondente a `image_description` usando um método idêntico ao que você explorou em `Image Search`.\n",
    "* **Etapa 4:** Combine todos os textos e imagens semelhantes encontrados nas etapas 2 e 3 como `context_text` e `context_images`.\n",
    "* **Etapa 5:** Com a ajuda do Gemini, podemos passar a consulta do usuário com o contexto de texto e imagem encontrado nas etapas 2 e 3. Você também pode adicionar uma instrução específica que o modelo deve lembrar ao responder à consulta do usuário.\n",
    "* **Etapa 6:** Gemini produz a resposta e você pode listar as citações para verificar todos os textos e imagens relevantes usados para responder à consulta."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "EI62Hzuw_0_b"
   },
   "source": [
    "### Etapa 1: Requisição do usuário"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "XvTKFwOPHLQ_",
    "tags": []
   },
   "outputs": [],
   "source": [
    "# this time we are not passing any images, but just a simple text query.\n",
    "\n",
    "query = \"\"\"Pergunta: Quais os melhores resultados, NASDAQ Composite ou ações Classe A do Google?\n",
    "Qual seria melhor comprar e por quê?\n",
    "Resposta: \"\"\"\n",
    "\n",
    "# query = \"\"\"Question: Find the total revenues and other related financial numbers for Alphabet\n",
    "# Answer: \"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "UUqlkKUaYvZA"
   },
   "source": [
    "### Etapa 2: Busca de todos os *chunks* de texto relevantes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "r65yBb5gR_NG",
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Retrieve relevant chunks of text based on the query\n",
    "matching_results_chunks_data = get_similar_text_from_query(\n",
    "    PROJECT_ID,\n",
    "    query,\n",
    "    text_metadata_df,\n",
    "    column_name=\"text_embedding_chunk\",\n",
    "    top_n=5,\n",
    "    embedding_size=1408,\n",
    "    chunk_text=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "mIgXgVIpYzxj"
   },
   "source": [
    "### Etapa 3: Busca de todas as imagens relevantes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "wzu5Gf4yR_J4",
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Get all relevant images based on user query\n",
    "matching_results_image_fromdescription_data = get_similar_image_from_query(\n",
    "    PROJECT_ID,\n",
    "    text_metadata_df,\n",
    "    image_metadata_df,\n",
    "    query=query,\n",
    "    column_name=\"text_embedding_from_image_description\",\n",
    "    image_emb=False,\n",
    "    top_n=3,\n",
    "    embedding_size=1408,\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "RhUpWlGAY2uG"
   },
   "source": [
    "### Step 4: Crie o `context_text` e o `context_images`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "B_EEuuLCe6Y5",
    "tags": []
   },
   "outputs": [],
   "source": [
    "# combine all the selected relevant text chunks\n",
    "context_text = []\n",
    "for key, value in matching_results_chunks_data.items():\n",
    "    context_text.append(value[\"chunk_text\"])\n",
    "final_context_text = \"\\n\".join(context_text)\n",
    "\n",
    "# combine all the relevant images and their description generated by Gemini\n",
    "context_images = []\n",
    "for key, value in matching_results_image_fromdescription_data.items():\n",
    "    context_images.extend(\n",
    "        [\"Imagem: \", value[\"image_object\"], \"Descrição: \", value[\"image_description\"]]\n",
    "    )\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "rHrtodcBAEu9"
   },
   "source": [
    "### Step 5: Passe o contexto ao Gemini"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "aTMnKzaDXVDC",
    "tags": []
   },
   "outputs": [],
   "source": [
    "instructions = \"\"\"O contexto de extração de informações deve ser baseado no contexto de texto fornecido em \"text_context\" e no contexto de imagem fornecido em \"image_context\" junto com sua legenda: \\n\n",
    "Baseie sua resposta em \"text_context\" e \"image_context\". Não utilize números ou porcentagens que não estejam presentes no \"image_context\".\n",
    "Utilize somente informações presentes no contexto, não utilize nenhuma outra informação. Considere apenas os anos citados no contexto.\n",
    "Não inclua nenhum retorno total cumulativo na resposta. Contexto:\n",
    "\"\"\"\n",
    "\n",
    "final_prompt = [\n",
    "    query,\n",
    "    instructions,\n",
    "    \"text_context:\",\n",
    "    \"\\n\".join(context_text),\n",
    "    \"image_context:\",\n",
    "]\n",
    "final_prompt.extend(context_images)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 133
    },
    "id": "Nko9i6ZfR-14",
    "outputId": "04a8cc63-eec8-4ea7-9508-5f4ed11feeb5",
    "tags": []
   },
   "outputs": [],
   "source": [
    "Markdown(get_gemini_response(model, model_input = final_prompt,stream=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 789
    },
    "id": "fP08CnTq6e_a",
    "outputId": "9cea3f0c-50e3-44a4-97e3-d249db674795",
    "tags": []
   },
   "outputs": [],
   "source": [
    "print(\"---------------Imagens encontradas------------------\\n\")\n",
    "display_images(\n",
    "    [\n",
    "        matching_results_image_fromdescription_data[0][\"img_path\"],\n",
    "        matching_results_image_fromdescription_data[1][\"img_path\"],\n",
    "    ],\n",
    "    resize_ratio = 0.8\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "L0FtXYl1fzKh"
   },
   "source": [
    "### Etapa 6: Liste citações e referências"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "buwd_gp6HJ5K",
    "outputId": "e47f790c-42fa-40ad-c2ad-b2f4ec41a68b",
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Image citations. You can check how Gemini generated metadata helped in grounding the answer.\n",
    "\n",
    "print_text_to_image_citation(matching_results_image_fromdescription_data, print_top=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "06vYM4MOHJ1-",
    "outputId": "ad644c38-977f-4389-fe82-ba7993489bde",
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Text citations\n",
    "\n",
    "print_text_to_text_citation(\n",
    "    matching_results_chunks_data,\n",
    "    print_top=False,\n",
    "    chunk_text=True,\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "KwNrHCqbi3xi"
   },
   "source": [
    "## Conclusões"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "05jynhZnkgxn"
   },
   "source": [
    "Embora o RAG multimodal possa ser bastante poderoso, observe que ele pode enfrentar algumas limitações:\n",
    "\n",
    "* **Dependência de dados:** precisa de texto e recursos visuais de alta qualidade.\n",
    "* **Computacionalmente exigente:** O processamento de dados multimodais consome muitos recursos.\n",
    "* **Específico do domínio:** Modelos treinados em dados gerais podem não brilhar em áreas especializadas como medicina.\n",
    "* **Opacidade dos modelos:** Compreender como esses modelos funcionam pode ser complicado, prejudicando a confiança e a adoção.\n",
    "\n",
    "Apesar destes desafios, o RAG multimodal representa um passo significativo em direção a sistemas de busca e recuperação que podem lidar com dados multimodais diversos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "provenance": [],
   "toc_visible": true
  },
  "environment": {
   "kernel": "python3",
   "name": "tf2-gpu.2-11.m109",
   "type": "gcloud",
   "uri": "gcr.io/deeplearning-platform-release/tf2-gpu.2-11:m109"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
