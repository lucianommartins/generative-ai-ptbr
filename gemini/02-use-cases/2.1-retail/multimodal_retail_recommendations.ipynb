{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ijGzTHJJUCPY"
   },
   "outputs": [],
   "source": [
    "# Copyright 2023 Google LLC\n",
    "#\n",
    "# Licensed under the Apache License, Version 2.0 (the \"License\");\n",
    "# you may not use this file except in compliance with the License.\n",
    "# You may obtain a copy of the License at\n",
    "#\n",
    "#     https://www.apache.org/licenses/LICENSE-2.0\n",
    "#\n",
    "# Unless required by applicable law or agreed to in writing, software\n",
    "# distributed under the License is distributed on an \"AS IS\" BASIS,\n",
    "# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
    "# See the License for the specific language governing permissions and\n",
    "# limitations under the License."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "VEqbX8OhE8y9"
   },
   "source": [
    "# Utilizando o Gemini para recomendação de produtos baseado em avaliação de imagens\n",
    "\n",
    "<table align=\"left\">\n",
    "  <td style=\"text-align: center\">\n",
    "    <a href=\"https://colab.research.google.com/github/GoogleCloudPlatform/generative-ai/blob/main/gemini/use-cases/retail/multimodal_retail_recommendations.ipynb\">\n",
    "      <img src=\"https://cloud.google.com/ml-engine/images/colab-logo-32px.png\" alt=\"Google Colaboratory logo\"><br> Executar no Colab\n",
    "    </a>\n",
    "  </td>\n",
    "  <td style=\"text-align: center\">\n",
    "    <a href=\"https://github.com/GoogleCloudPlatform/generative-ai/blob/main/gemini/use-cases/retail/multimodal_retail_recommendations.ipynb\">\n",
    "      <img src=\"https://cloud.google.com/ml-engine/images/github-logo-32px.png\" alt=\"GitHub logo\"><br> Ver no GitHub\n",
    "    </a>\n",
    "  </td>\n",
    "  <td style=\"text-align: center\">\n",
    "    <a href=\"https://console.cloud.google.com/vertex-ai/workbench/deploy-notebook?download_url=https://raw.githubusercontent.com/GoogleCloudPlatform/generative-ai/blob/main/gemini/use-cases/retail/multimodal_retail_recommendations.ipynb\">\n",
    "      <img src=\"https://lh3.googleusercontent.com/UiNooY4LUgW_oTvpsNhPpQzsstV5W8F7rYgxgGBD85cWJoLmrOzhVs_ksK_vgx40SHs7jCqkTkCk=e14-rj-sc0xffffff-h130-w32\" alt=\"Vertex AI logo\"><br> Abrir no Workbench da Vertex AI\n",
    "    </a>\n",
    "  </td>\n",
    "</table>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "VK1Q5ZYdVL4Y"
   },
   "source": [
    "## Visão geral\n",
    "\n",
    "Para empresas de varejo, os sistemas de recomendação melhoram a experiência do cliente e, portanto, podem aumentar as vendas.\n",
    "\n",
    "Este notebook mostra como você pode usar os recursos multimodais do modelo Gemini Pro Vision para criar rapidamente um sistema de recomendação multimodal pronto para uso."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "3zLxCZkKEAhC",
    "tags": []
   },
   "source": [
    "## Scenario\n",
    "\n",
    "O cliente mostra sua sala de estar:\n",
    "\n",
    "|Foto do cliente |\n",
    "|:-----:|\n",
    "|<img src=\"https://storage.googleapis.com/github-repo/img/gemini/retail-recommendations/rooms/spacejoy-c0JoR_-2x3E-unsplash.jpg\" width=\"80%\">  |\n",
    "\n",
    "\n",
    "\n",
    "Abaixo há quatro opções de cadeiras que o cliente está tentando decidir em sua compra:\n",
    "\n",
    "|Cadeira 1| Cadeira 2 | Cadeira 3 | cadeira 4 |\n",
    "|:-----:|:----:|:-----:|:----:|\n",
    "| <img src=\"https://storage.googleapis.com/github-repo/img/gemini/retail-recommendations/furnitures/cesar-couto-OB2F6CsMva8-unsplash.jpg\" width=\"80%\">|<img src=\"https://storage.googleapis.com/github-repo/img/gemini/retail-recommendations/furnitures/daniil-silantev-1P6AnKDw6S8-unsplash.jpg\" width=\"80%\">|<img src=\"https://storage.googleapis.com/github-repo/img/gemini/retail-recommendations/furnitures/ruslan-bardash-4kTbAMRAHtQ-unsplash.jpg\" width=\"80%\">|<img src=\"https://storage.googleapis.com/github-repo/img/gemini/retail-recommendations/furnitures/scopic-ltd-NLlWwR4d3qU-unsplash.jpg\" width=\"80%\">|\n",
    "\n",
    "\n",
    "Você terá aqui um exercício de como utilizar o `Gemini Pro Vision` para acelerar a solução deste tipo de cenário."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "RQT500QqVPIb"
   },
   "source": [
    "### Objetivos\n",
    "\n",
    "Seu principal objetivo é aprender como criar um sistema de recomendação que possa fornecer recomendações e explicações usando um modelo multimodal: `Gemini Pro Vision`.\n",
    "\n",
    "Neste notebook, você começará com uma cena (por exemplo, uma sala de estar) e usará o modelo `Gemini Pro Vision` para realizar a compreensão visual. Você também investigará como o modelo `Gemini Pro Vision` pode ser usado para recomendar um item (por exemplo, uma cadeira) de uma lista de itens de mobiliário como entrada.\n",
    "\n",
    "Neste notebook você aprenderá:\n",
    "- como usar o modelo `Gemini Pro Vision` para realizar a compreensão visual\n",
    "- como levar em consideração a multimodalidade ao solicitar o modelo `Gemini Pro Vision`\n",
    "- como o modelo `Gemini Pro Vision` pode ser usado para criar aplicativos de recomendação de varejo prontos para uso"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "1y6_3dTwV2fI"
   },
   "source": [
    "### Custos\n",
    "\n",
    "Este tutorial usa os seguintes componentes de Google Cloud que podem gerar custos em sua fatura:\n",
    "\n",
    "- Vertex AI\n",
    "\n",
    "Saiba mais sobre [preços da Vertex AI](https://cloud.google.com/vertex-ai/pricing) e use a [calculadora de preços](https://cloud.google.com/products/calculator/) para gerar uma estimativa de custo com base no uso projetado.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "QDU0XJ1xRDlL"
   },
   "source": [
    "## Primeiros passos"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "N5afkyDMSBW5"
   },
   "source": [
    "### Instale a SDK da Vertex AI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "V_-ThW_ZUYRV"
   },
   "outputs": [],
   "source": [
    "! pip3 install --upgrade --user google-cloud-aiplatform"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "j7UyNVSiyQ96"
   },
   "source": [
    "### **Somente para uso no Colab - Reinicie o kernel do notebook** \n",
    "\n",
    "Caso você esteja executando este notebook no Google Colab, descomente a célula abaixo para realizar o restart do kernel do notebook (etapa importante para que o Colab reconheça a nova versão da SDK) e a execute. Senão, siga para as próximas instruções."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "YmY9HVVGSBW5",
    "tags": []
   },
   "outputs": [],
   "source": [
    "# import IPython\n",
    "\n",
    "# app = IPython.Application.instance()\n",
    "# app.kernel.do_shutdown(True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "6Fom0ZkMSBW6"
   },
   "source": [
    "### **Somente para uso no Colab - Autentique o seu ambiente de notebook** \n",
    "\n",
    "Caso você esteja executando este notebook no Google Colab, descomente a célula abaixo para realizar a autenticação da sua sessão de notebook com a Google Cloud Esse passo é importante **para utilização no Colab** para garantir que as chamadas a APIs de Google Cloud funcionem sem problemas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "LCaCx6PLSBW6",
    "tags": []
   },
   "outputs": [],
   "source": [
    "# import sys\n",
    "\n",
    "# # Additional authentication is required for Google Colab\n",
    "# if 'google.colab' in sys.modules:\n",
    "\n",
    "#     # Authenticate user to Google Cloud\n",
    "#     from google.colab import auth\n",
    "\n",
    "#     auth.authenticate_user()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "BuQwwRiniVFG"
   },
   "source": [
    "### **Somente para uso no Colab - defina o projeto Google Cloud a ser utilizado** \n",
    "\n",
    "Caso você esteja executando este notebook no Google Colab, descomente a célula abaixo para definir qual projeto Google Cloud será utilizado pelo Colab na execução deste notebook. Senão, siga para as próximas instruções."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "rtMowvm-yQ97",
    "tags": []
   },
   "outputs": [],
   "source": [
    "# if 'google.colab' in sys.modules:\n",
    "\n",
    "#     # Define project information\n",
    "#     PROJECT_ID = \"[your-project-id]\" # @param {type:\"string\"}\n",
    "#     LOCATION = \"us-central1\" # @param {type:\"string\"}\n",
    "\n",
    "#     # Initialize Vertex AI\n",
    "#     import vertexai\n",
    "\n",
    "#     vertexai.init(project=PROJECT_ID, location=LOCATION)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "4437b7608c8e"
   },
   "source": [
    "### Importando as bibliotecas necessárias"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "yZ75ioBU9EwM",
    "tags": []
   },
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '3' \n",
    "\n",
    "import warnings\n",
    "warnings.simplefilter(\"ignore\", UserWarning)\n",
    "\n",
    "from vertexai.preview.generative_models import GenerativeModel, Image"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "hhcZv4HFUYRW"
   },
   "source": [
    "## Importando o modelo `Gemini Pro Vision`\n",
    "\n",
    "O modelo Gemini Pro Vision `gemini-pro-vision` é um modelo multimodal que suporta a adição de imagem e vídeo em texto ou prompts de chat para uma resposta de texto."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "pxlvLmncUYRW",
    "tags": []
   },
   "outputs": [],
   "source": [
    "multimodal_model = GenerativeModel(\"gemini-pro-vision\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "sNxn74L2UNdU"
   },
   "source": [
    "### Defina algumas funções auxiliares\n",
    "\n",
    "Defina funções auxiliares para carregar e exibir imagens."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "VEUnTOHz95vm",
    "tags": []
   },
   "outputs": [],
   "source": [
    "import http.client\n",
    "import io\n",
    "import typing\n",
    "import urllib.request\n",
    "\n",
    "import IPython.display\n",
    "from PIL import Image as PIL_Image\n",
    "from PIL import ImageOps as PIL_ImageOps\n",
    "\n",
    "def display_image(image: Image,\n",
    "                  max_width: int = 600,\n",
    "                  max_height: int = 350) -> None:\n",
    "    pil_image = typing.cast(PIL_Image.Image, image._pil_image)\n",
    "    if pil_image.mode != \"RGB\":\n",
    "        # Modes such as RGBA are not yet supported by all Jupyter environments\n",
    "        pil_image = pil_image.convert(\"RGB\")\n",
    "    image_width, image_height = pil_image.size\n",
    "    if max_width < image_width or max_height < image_height:\n",
    "        # Resize to display a smaller notebook image\n",
    "        pil_image = PIL_ImageOps.contain(pil_image, (max_width, max_height))\n",
    "    display_image_compressed(pil_image)\n",
    "\n",
    "\n",
    "def display_image_compressed(pil_image: PIL_Image.Image) -> None:\n",
    "    image_io = io.BytesIO()\n",
    "    pil_image.save(image_io, \"jpeg\", quality=80, optimize=True)\n",
    "    image_bytes = image_io.getvalue()\n",
    "    ipython_image = IPython.display.Image(image_bytes)\n",
    "    IPython.display.display(ipython_image)\n",
    "\n",
    "\n",
    "def get_image_bytes_from_url(image_url: str) -> bytes:\n",
    "    with urllib.request.urlopen(image_url) as response:\n",
    "        response = typing.cast(http.client.HTTPResponse, response)\n",
    "        if response.headers[\"Content-Type\"] not in (\"image/png\", \"image/jpeg\"):\n",
    "            raise Exception(\"Image can only be in PNG or JPEG format\")\n",
    "        image_bytes = response.read()\n",
    "    return image_bytes\n",
    "\n",
    "\n",
    "def load_image_from_url(image_url: str) -> Image:\n",
    "    image_bytes = get_image_bytes_from_url(image_url)\n",
    "    return Image.from_bytes(image_bytes)\n",
    "\n",
    "\n",
    "def print_multimodal_prompt(contents: list):\n",
    "    \"\"\"\n",
    "    Given contents that would be sent to Gemini,\n",
    "    output the full multimodal prompt for ease of readability.\n",
    "    \"\"\"\n",
    "    for content in contents:\n",
    "        if isinstance(content, Image):\n",
    "            display_image(content)\n",
    "        else:\n",
    "            print(content)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "MONqa2K8IjSz"
   },
   "source": [
    "### Compreensão visual com `Gemini Pro Vision`\n",
    "\n",
    "Aqui você pedirá ao modelo Gemini Pro Vision para descrever uma sala em detalhes a partir de sua imagem. Para fazer isso você precisa **combinar texto e imagem em um único prompt**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "26wP-epVFBBK",
    "tags": []
   },
   "outputs": [],
   "source": [
    "# urls for room images\n",
    "room_image_url = \"https://storage.googleapis.com/github-repo/img/gemini/retail-recommendations/rooms/spacejoy-c0JoR_-2x3E-unsplash.jpg\"\n",
    "\n",
    "# load room images as Image Objects\n",
    "room_image = load_image_from_url(room_image_url)\n",
    "\n",
    "prompt = \"Descreva o que é visível nesta sala e sua atmosfera geral:\"\n",
    "contents = [\n",
    "    prompt,\n",
    "    room_image,\n",
    "]\n",
    "\n",
    "responses = multimodal_model.generate_content(contents, stream=True)\n",
    "\n",
    "print(\"-------Prompt--------\")\n",
    "print_multimodal_prompt(contents)\n",
    "\n",
    "print(\"\\n-------Resposta--------\")\n",
    "for response in responses:\n",
    "    print(response.text, end=\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "64I8-GxSbkTv"
   },
   "source": [
    "### Gerando recomendações abertas com base em conhecimento integrado\n",
    "\n",
    "Usando a mesma imagem, você pode pedir ao modelo que recomende **um móvel** que caiba nele junto com a descrição do ambiente.\n",
    "\n",
    "Observe que o modelo pode escolher **qualquer móvel** recomendado neste caso, e pode fazê-lo a partir de seu único conhecimento integrado."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "UaRDl1WvypT8",
    "tags": []
   },
   "outputs": [],
   "source": [
    "prompt1 = \"Recomende um novo móvel para esta sala:\"\n",
    "prompt2 = \"e explique a razão em detalhes\"\n",
    "contents = [\n",
    "    prompt1,\n",
    "    room_image,\n",
    "    prompt2\n",
    "]\n",
    "\n",
    "responses = multimodal_model.generate_content(contents, stream=True)\n",
    "\n",
    "print(\"-------Prompt--------\")\n",
    "print_multimodal_prompt(contents)\n",
    "\n",
    "print(\"\\n-------Resposta--------\")\n",
    "for response in responses:\n",
    "    print(response.text, end=\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "lzdaG4iIdZM8"
   },
   "source": [
    "Na próxima célula, você pedirá ao modelo que recomende **um tipo de cadeira** que caiba nela junto com a descrição do ambiente.\n",
    "\n",
    "Observe que o modelo pode escolher **qualquer tipo de cadeira** para recomendar neste caso."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "h7xKDMFLyQuD",
    "tags": []
   },
   "outputs": [],
   "source": [
    "prompt1 = \"Descreva esta sala:\"\n",
    "prompt2 = \"e recomende um tipo de cadeira que combine com ela\"\n",
    "contents = [\n",
    "    prompt1,\n",
    "    room_image,\n",
    "    prompt2\n",
    "]\n",
    "\n",
    "responses = multimodal_model.generate_content(contents, stream=True)\n",
    "\n",
    "print(\"-------Prompt--------\")\n",
    "print_multimodal_prompt(contents)\n",
    "\n",
    "print(\"\\n-------Resposta--------\")\n",
    "for response in responses:\n",
    "    print(response.text, end=\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "idEB0JFcbznD"
   },
   "source": [
    "### Gerando recomendações com base nas imagens fornecidas\n",
    "\n",
    "Em vez de manter a recomendação aberta, você também pode fornecer uma lista de itens para o modelo escolher. \n",
    "\n",
    "Aqui você baixará algumas imagens de cadeiras e as definirá como opções para o modelo Gemini recomendar. Isto é particularmente útil para empresas de varejo que desejam fornecer recomendações aos usuários com base no tipo de quarto que possuem e nos itens disponíveis que a loja oferece."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "f_jMmwRiFcPF",
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Download and display sample chairs\n",
    "furniture_image_urls = [\n",
    "    \"https://storage.googleapis.com/github-repo/img/gemini/retail-recommendations/furnitures/cesar-couto-OB2F6CsMva8-unsplash.jpg\",\n",
    "    \"https://storage.googleapis.com/github-repo/img/gemini/retail-recommendations/furnitures/daniil-silantev-1P6AnKDw6S8-unsplash.jpg\",\n",
    "    \"https://storage.googleapis.com/github-repo/img/gemini/retail-recommendations/furnitures/ruslan-bardash-4kTbAMRAHtQ-unsplash.jpg\",\n",
    "    \"https://storage.googleapis.com/github-repo/img/gemini/retail-recommendations/furnitures/scopic-ltd-NLlWwR4d3qU-unsplash.jpg\",\n",
    "]\n",
    "\n",
    "# Load furniture images as Image Objects\n",
    "furniture_images = [load_image_from_url(url) for url in furniture_image_urls]\n",
    "\n",
    "# To recommend an item from a selection, you will need to label the item number within the prompt.\n",
    "# That way you are providing the model with a way to reference each image as you pose a question.\n",
    "# Labelling images within your prompt also help to reduce hallucinations and overall produce better results.\n",
    "contents = [\n",
    "    \"Considere as seguintes cadeiras:\",\n",
    "    \"cadeira 1:\", furniture_images[0],\n",
    "    \"cadeira 2:\", furniture_images[1],\n",
    "    \"cadeira 3:\", furniture_images[2],\n",
    "    \"cadeira 4:\", furniture_images[3], \n",
    "    \"sala:\",\n",
    "    room_image,\n",
    "    \"Você é um designer de interiores. Para cada cadeira, explique se ela seria apropriada ou não para o estilo da sala. Sumarize quais as duas melhores opções de cadeira:\",\n",
    "]\n",
    "\n",
    "responses = multimodal_model.generate_content(contents, stream=True)\n",
    "\n",
    "print(\"-------Prompt--------\")\n",
    "print_multimodal_prompt(contents)\n",
    "\n",
    "print(\"\\n-------Resposta--------\")\n",
    "for response in responses:\n",
    "    print(response.text, end=\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Mkw-DixOUYRc"
   },
   "source": [
    "Você pode também pedir a resposta em algum formato específico, como JSON por exemplo, para simplificar a integração da resposta do modelo com algum sistema de recomendações já existente em seu ambiente:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "MDBQufRYUYRc",
    "tags": []
   },
   "outputs": [],
   "source": [
    "contents = [\n",
    "    \"Considere as seguintes cadeiras:\",\n",
    "    \"cadeira 1:\", furniture_images[0],\n",
    "    \"cadeira 2:\", furniture_images[1],\n",
    "    \"cadeira 3:\", furniture_images[2],\n",
    "    \"cadeira 4:\", furniture_images[3], \n",
    "    \"sala:\",\n",
    "    room_image,\n",
    "    \"Você é um designer de interiores. Retorne em JSON, para cada cadeira, se ela seria uma boa escolha ou não para esta sala, incluindo uma explicação da decisão:\",\n",
    "]\n",
    "\n",
    "responses = multimodal_model.generate_content(contents, stream=True)\n",
    "\n",
    "print(\"-------Prompt--------\")\n",
    "print_multimodal_prompt(contents)\n",
    "\n",
    "print(\"\\n-------Resposta--------\")\n",
    "for response in responses:\n",
    "    print(response.text, end=\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "0_uhGdZERToX"
   },
   "source": [
    "## Conclusão\n",
    "\n",
    "Este notebook mostrou como você pode construir facilmente um sistema de recomendação multimodal usando Gemini para móveis, mas também pode usar uma abordagem semelhante em:\n",
    "\n",
    "- recomendar roupas com base em uma ocasião ou imagem do local\n",
    "- recomendação de papel de parede com base na sala e nas configurações\n",
    "\n",
    "Você também pode querer explorar como você pode construir um sistema RAG, onde você recupera imagens relevantes do inventário de sua loja para usuários que podem usar o Gemini para ajudar a identificar a escolha mais ideal entre as várias opções fornecidas, e também explicar a lógica aos usuários."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "provenance": [],
   "toc_visible": true
  },
  "environment": {
   "kernel": "python3",
   "name": "tf2-gpu.2-11.m109",
   "type": "gcloud",
   "uri": "gcr.io/deeplearning-platform-release/tf2-gpu.2-11:m109"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
