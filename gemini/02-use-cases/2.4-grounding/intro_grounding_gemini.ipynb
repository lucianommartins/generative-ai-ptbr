{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ijGzTHJJUCPY"
   },
   "outputs": [],
   "source": [
    "# Copyright 2023 Google LLC\n",
    "#\n",
    "# Licensed under the Apache License, Version 2.0 (the \"License\");\n",
    "# you may not use this file except in compliance with the License.\n",
    "# You may obtain a copy of the License at\n",
    "#\n",
    "#     https://www.apache.org/licenses/LICENSE-2.0\n",
    "#\n",
    "# Unless required by applicable law or agreed to in writing, software\n",
    "# distributed under the License is distributed on an \"AS IS\" BASIS,\n",
    "# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
    "# See the License for the specific language governing permissions and\n",
    "# limitations under the License."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "VEqbX8OhE8y9"
   },
   "source": [
    "# *Grounding* usando a Vertex AI Gemini API\n",
    "\n",
    "<table align=\"left\">\n",
    "  <td style=\"text-align: center\">\n",
    "    <a href=\"https://colab.research.google.com/github/GoogleCloudPlatform/generative-ai/blob/main/gemini/use-cases/retrieval-augmented-generation/intro_multimodal_rag.ipynb\">\n",
    "      <img src=\"https://cloud.google.com/ml-engine/images/colab-logo-32px.png\" alt=\"Google Colaboratory logo\"><br> Execute no Colab\n",
    "    </a>\n",
    "  </td>\n",
    "  <td style=\"text-align: center\">\n",
    "    <a href=\"https://github.com/GoogleCloudPlatform/generative-ai/blob/main/gemini/use-cases/retrieval-augmented-generation/intro_multimodal_rag.ipynb\">\n",
    "      <img src=\"https://cloud.google.com/ml-engine/images/github-logo-32px.png\" alt=\"GitHub logo\"><br> Veja no GitHub\n",
    "    </a>\n",
    "  </td>\n",
    "  <td style=\"text-align: center\">\n",
    "    <a href=\"https://console.cloud.google.com/vertex-ai/workbench/deploy-notebook?download_url=https://raw.githubusercontent.com/GoogleCloudPlatform/generative-ai/blob/main/gemini/use-cases/retrieval-augmented-generation/intro_multimodal_rag.ipynb\">\n",
    "      <img src=\"https://lh3.googleusercontent.com/UiNooY4LUgW_oTvpsNhPpQzsstV5W8F7rYgxgGBD85cWJoLmrOzhVs_ksK_vgx40SHs7jCqkTkCk=e14-rj-sc0xffffff-h130-w32\" alt=\"Vertex AI logo\"><br> Abra no Workbench da Vertex AI\n",
    "    </a>\n",
    "  </td>\n",
    "</table>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "VK1Q5ZYdVL4Y"
   },
   "source": [
    "## Visão geral\n",
    "\n",
    "O *Grounding* permite usar modelos de texto generativos para gerar conteúdo baseado em seus próprios documentos e dados. Esse recurso permite que o modelo acesse informações em tempo de execução que vão além dos dados de treinamento. Ao basear as respostas do modelo nos resultados da Pesquisa Google ou nos armazenamentos de dados no Vertex AI Search, os LLMs baseados em dados podem produzir respostas mais precisas, atualizadas e relevantes.\n",
    "\n",
    "O *grounding* oferece os seguintes benefícios:\n",
    "\n",
    "- Reduz as alucinações do modelo (casos em que o modelo gera conteúdo que não é factual)\n",
    "- Ancora respostas do modelo a informações, documentos e fontes de dados específicas\n",
    "- Aumenta a confiabilidade, precisão e aplicabilidade do conteúdo gerado\n",
    "\n",
    "No contexto de aterramento na Vertex AI, é possível configurar duas fontes diferentes de aterramento:\n",
    "\n",
    "1. Resultados da Pesquisa Google para dados disponíveis publicamente e indexados\n",
    "2. Armazenamentos de dados no Vertex AI Search, que podem incluir seus próprios dados na forma de dados de sites, dados não estruturados ou dados estruturados\n",
    "\n",
    "**NOTA**: Alguns dos recursos deste notebook de exemplo exigem acesso antecipado a determinados recursos por meio de uma lista de permissões. O Grounding with Vertex AI Search está disponível na visualização pública, enquanto o Grounding with Google Web Search está disponível na visualização privada. Para solicitar acesso antecipado aos recursos da visualização privada, entre em contato com o representante da sua conta ou com o suporte do Google Cloud."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "RQT500QqVPIb"
   },
   "source": [
    "### Objetivos\n",
    "\n",
    "Neste tutorial, você aprende como:\n",
    "\n",
    "- Gere respostas de modelo de bate-papo e texto LLM com base nos resultados da Pesquisa Google\n",
    "- Compare os resultados de respostas LLM não fundamentadas com respostas LLM fundamentadas\n",
    "- Crie e use um armazenamento de dados no Vertex AI Search para basear respostas em documentos e dados personalizados\n",
    "- Gere respostas de modelo de chat e texto LLM com base nos resultados do Vertex AI Search\n",
    "\n",
    "Este tutorial usa os seguintes serviços e recursos de IA do Google Cloud:\n",
    "- Vertex AI\n",
    "- Pesquisa e conversação da Vertex AI\n",
    "\n",
    "As etapas executadas incluem:\n",
    "\n",
    "- Configurando o LLM e solicitando vários exemplos\n",
    "- Envio de prompts de exemplo para modelos generativos de texto e chat na Vertex AI\n",
    "- Configurar um armazenamento de dados no Vertex AI Search com seus próprios dados\n",
    "- Envio de prompts de exemplo com vários níveis de aterramento (sem aterramento, aterramento na web, aterramento no armazenamento de dados)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Custos\n",
    "\n",
    "Este tutorial usa os seguintes componentes de Google Cloud que podem gerar custos em sua fatura:\n",
    "\n",
    "- Vertex AI\n",
    "\n",
    "Saiba mais sobre [preços da Vertex AI](https://cloud.google.com/vertex-ai/pricing) e use a [calculadora de preços](https://cloud.google.com/products/calculator/) para gerar uma estimativa de custo com base no uso projetado."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Primeiros passos"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "N5afkyDMSBW5"
   },
   "source": [
    "### Instale a SDK da Vertex AI\n",
    "**Importante:** só descomente a linha abaixo se você **não estiver** executando este laboratório no Qwiklabs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "kc4WxYmLSBW5",
    "outputId": "64a92007-dee1-4629-bee6-a3fa43d79b47",
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "# ! pip3 install --upgrade --user google-cloud-aiplatform pymupdf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "j7UyNVSiyQ96"
   },
   "source": [
    "### **Reinicie o kernel do seu jupyter notebook** \n",
    "\n",
    "Como a instalação está sendo realizada com a opção `--user` é necessário reiniciar o kernel para que os novos módulos se tornem acessíveis.\n",
    "\n",
    "**Importante:** só descomente a linha abaixo se você **não estiver** executando este laboratório no Qwiklabs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "YmY9HVVGSBW5",
    "outputId": "508067b0-486c-445b-fad5-6480f495eba0",
    "tags": []
   },
   "outputs": [],
   "source": [
    "# import IPython\n",
    "\n",
    "# app = IPython.Application.instance()\n",
    "# app.kernel.do_shutdown(True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "<div class=\"alert alert-block alert-warning\">\n",
    "<b>⚠️ O kernel do notebook está sendo reiniciado. Por favor aguarde este processo ser finalizado antes de continuar com os próximos passos. ⚠️</b>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Somente para uso no Colab - Autentique o seu ambiente de notebook** \n",
    "\n",
    "Caso você esteja executando este notebook no Google Colab, descomente a célula abaixo para realizar a autenticação da sua sessão de notebook com a Google Cloud Esse passo é importante **para utilização no Colab** para garantir que as chamadas a APIs de Google Cloud funcionem sem problemas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# import sys\n",
    "\n",
    "# # Additional authentication is required for Google Colab\n",
    "# if \"google.colab\" in sys.modules:\n",
    "#     # Authenticate user to Google Cloud\n",
    "#     from google.colab import auth\n",
    "\n",
    "#     auth.authenticate_user()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Somente para uso no Colab - defina o projeto Google Cloud a ser utilizado** \n",
    "\n",
    "Caso você esteja executando este notebook no Google Colab, descomente a célula abaixo para definir qual projeto Google Cloud será utilizado pelo Colab na execução deste notebook. Senão, siga para as próximas instruções."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# if \"google.colab\" in sys.modules:\n",
    "#     # Define project information\n",
    "#     PROJECT_ID = \"[your-project-id]\"  # @param {type:\"string\"}\n",
    "#     LOCATION = \"us-central1\"  # @param {type:\"string\"}\n",
    "\n",
    "#     # Initialize Vertex AI\n",
    "#     import vertexai\n",
    "\n",
    "#     vertexai.init(project=PROJECT_ID, location=LOCATION)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "BuQwwRiniVFG"
   },
   "source": [
    "### Importe as bibliotecas necessárias"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "rtMowvm-yQ97",
    "tags": []
   },
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '3' \n",
    "\n",
    "import warnings\n",
    "warnings.simplefilter(\"ignore\", UserWarning)\n",
    "\n",
    "from IPython.display import Markdown, display\n",
    "from vertexai.generative_models import (\n",
    "    Content,\n",
    "    GenerationConfig,\n",
    "    GenerationResponse,\n",
    "    GenerativeModel,\n",
    "    Image,\n",
    "    Part\n",
    ")\n",
    "\n",
    "from vertexai.preview.generative_models import (\n",
    "    Tool, \n",
    "    grounding\n",
    ")\n",
    "\n",
    "PROJECT_ID = \"lucianomartins-demos-345000\"  # @param {type:\"string\"}\n",
    "LOCATION = \"us-central1\"  # @param {type:\"string\"}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Importe o modelo `Gemini 1.0 Pro`\n",
    "\n",
    "O Gemini Pro (`gemini-1.0-pro`) ajuda na realização de tarefas utilizando linguagem natural, chats multiturno de texto e código e para a geração de código."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "model = GenerativeModel(\"gemini-1.0-pro-vision\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exemplo: baseando-se nos resultados da Pesquisa Google\n",
    "\n",
    "Neste exemplo, você comparará respostas LLM sem fundamento com respostas baseadas nos resultados de uma Pesquisa Google. Você fará uma pergunta sobre um lançamento recente de hardware da Google Store."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "prompt = (\n",
    "    \"Quais são o preço, cores disponíveis e opções de armazenamento do último Pixel Tablet lançado?\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Texto gerado sem *grounding*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "response = model.generate_content(prompt)\n",
    "\n",
    "display(Markdown(response.candidates[0].text))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Geração de texto com base nos resultados da Pesquisa Google\n",
    "\n",
    "Agora você pode adicionar a palavra-chave de ferramentas arg com uma ferramenta de *grounding* `grounding.GoogleSearchRetrieval()` para instruir o LLM a primeiro realizar uma pesquisa no Google com o prompt e, em seguida, construir uma resposta com base nos resultados da pesquisa na web:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "tool = Tool.from_google_search_retrieval(grounding.GoogleSearchRetrieval())\n",
    "response = model.generate_content(prompt, tools=[tool])\n",
    "display(Markdown(response.candidates[0].text))\n",
    "response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "provenance": [],
   "toc_visible": true
  },
  "environment": {
   "kernel": "python3",
   "name": "tf2-cpu.2-11.m117",
   "type": "gcloud",
   "uri": "us-docker.pkg.dev/deeplearning-platform-release/gcr.io/tf2-cpu.2-11:m117"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
