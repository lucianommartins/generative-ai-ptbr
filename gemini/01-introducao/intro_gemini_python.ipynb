{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ijGzTHJJUCPY"
   },
   "outputs": [],
   "source": [
    "# Copyright 2023 Google LLC\n",
    "#\n",
    "# Licensed under the Apache License, Version 2.0 (the \"License\");\n",
    "# you may not use this file except in compliance with the License.\n",
    "# You may obtain a copy of the License at\n",
    "#\n",
    "#     https://www.apache.org/licenses/LICENSE-2.0\n",
    "#\n",
    "# Unless required by applicable law or agreed to in writing, software\n",
    "# distributed under the License is distributed on an \"AS IS\" BASIS,\n",
    "# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
    "# See the License for the specific language governing permissions and\n",
    "# limitations under the License."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "VEqbX8OhE8y9"
   },
   "source": [
    "# Primeiros Passos com a Vertex AI Gemini API & Python SDK\n",
    "\n",
    "<table align=\"left\">\n",
    "  <td style=\"text-align: center\">\n",
    "    <a href=\"https://colab.research.google.com/github/GoogleCloudPlatform/generative-ai/blob/main/gemini/getting-started/intro_gemini_python.ipynb\">\n",
    "      <img src=\"https://cloud.google.com/ml-engine/images/colab-logo-32px.png\" alt=\"Google Colaboratory logo\"><br> Executar no Colab\n",
    "    </a>\n",
    "  </td>\n",
    "  <td style=\"text-align: center\">\n",
    "    <a href=\"https://github.com/GoogleCloudPlatform/generative-ai/blob/main/gemini/getting-started/intro_gemini_python.ipynb\">\n",
    "      <img src=\"https://cloud.google.com/ml-engine/images/github-logo-32px.png\" alt=\"GitHub logo\"><br> Ver no GitHub\n",
    "    </a>\n",
    "  </td>\n",
    "  <td style=\"text-align: center\">\n",
    "    <a href=\"https://console.cloud.google.com/vertex-ai/workbench/deploy-notebook?download_url=https://raw.githubusercontent.com/GoogleCloudPlatform/generative-ai/blob/main/gemini/getting-started/intro_gemini_python.ipynb\">\n",
    "      <img src=\"https://lh3.googleusercontent.com/UiNooY4LUgW_oTvpsNhPpQzsstV5W8F7rYgxgGBD85cWJoLmrOzhVs_ksK_vgx40SHs7jCqkTkCk=e14-rj-sc0xffffff-h130-w32\" alt=\"Vertex AI logo\"><br> Abrir no Workbench da Vertex AI\n",
    "    </a>\n",
    "  </td>\n",
    "</table>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "CkHPv2myT2cx"
   },
   "source": [
    "## Visão Geral\n",
    "\n",
    "### Gemini\n",
    "\n",
    "Gemini é uma família de modelos generativos de IA desenvolvidos pelo Google DeepMind e projetados para casos de uso multimodais. A API Gemini dá acesso aos modelos Gemini Pro Vision e Gemini Pro.\n",
    "\n",
    "### API Vertex AI Gemini\n",
    "\n",
    "A API Vertex AI Gemini fornece uma interface unificada para interagir com modelos Gemini. Atualmente existem dois modelos disponíveis na API Gemini:\n",
    "\n",
    "- **Modelo Gemini Pro** (`gemini-pro`): Projetado para lidar com tarefas de linguagem natural, bate-papo multivoltas de texto e código e geração de código.\n",
    "- **Modelo Gemini Pro Vision** (`gemini-pro-vision`): Suporta prompts multimodais. Você pode incluir texto, imagens e vídeo em suas solicitações de prompt e obter respostas em texto ou código.\n",
    "\n",
    "Você pode interagir com a API Gemini usando os seguintes métodos:\n",
    "\n",
    "- Use o [Vertex AI Studio](https://cloud.google.com/generative-ai-studio) para testes rápidos e geração de comandos\n",
    "- Use o SDK da Vertex AI\n",
    "\n",
    "Este notebook se concentra no uso do **Vertex AI SDK para Python** para chamar a API Vertex AI Gemini.\n",
    "\n",
    "Para obter mais informações, consulte a documentação [IA Generativa na Vertex AI](https://cloud.google.com/vertex-ai/docs/generative-ai/learn/overview)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "DrkcqHrrwMAo"
   },
   "source": [
    "### Objetivos\n",
    "\n",
    "Neste tutorial, você aprenderá como usar a API Vertex AI Gemini com o SDK Vertex AI para Python para interagir com os modelos Gemini Pro (`gemini-pro`) e o Gemini Pro Vision (`gemini-pro-vision`).\n",
    "\n",
    "Você concluirá as seguintes tarefas:\n",
    "\n",
    "- Instalar o SDK da Vertex AI para Python\n",
    "- Usar a API Vertex AI Gemini para interagir com cada modelo\n",
    "   - Modelo Gemini Pro (`gemini-pro`):\n",
    "     - Gere texto a partir de prompts de texto\n",
    "     - Explore vários recursos e opções de configuração\n",
    "   - Modelo Gemini Pro Vision (`gemini-pro-vision`):\n",
    "     - Gere texto a partir de imagens e prompts de texto\n",
    "     - Gere texto a partir de prompts de vídeo e texto"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "C9nEPojogw-g"
   },
   "source": [
    "### Custos\n",
    "\n",
    "Este tutorial usa os seguintes componentes de Google Cloud que podem gerar custos em sua fatura:\n",
    "\n",
    "- Vertex AI\n",
    "\n",
    "Saiba mais sobre [preços da Vertex AI](https://cloud.google.com/vertex-ai/pricing) e use a [calculadora de preços](https://cloud.google.com/products/calculator/) para gerar uma estimativa de custo com base no uso projetado."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "r11Gu7qNgx1p"
   },
   "source": [
    "## Primeiros passos"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "No17Cw5hgx12"
   },
   "source": [
    "### Instale a SDK da Vertex AI\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "tFy3H3aPgx12",
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "! pip3 install --upgrade --user google-cloud-aiplatform"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "j7UyNVSiyQ96",
    "tags": []
   },
   "source": [
    "### **Somente para uso no Colab - Reinicie o kernel do notebook** \n",
    "\n",
    "Caso você esteja executando este notebook no Google Colab, descomente a célula abaixo para realizar o restart do kernel do notebook (etapa importante para que o Colab reconheça a nova versão da SDK) e a execute. Senão, siga para as próximas instruções."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "YmY9HVVGSBW5",
    "tags": []
   },
   "outputs": [],
   "source": [
    "# import IPython\n",
    "\n",
    "# app = IPython.Application.instance()\n",
    "# app.kernel.do_shutdown(True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "dmWOrTJ3gx13"
   },
   "source": [
    "### **Somente para uso no Colab - Autentique o seu ambiente de notebook** \n",
    "\n",
    "Caso você esteja executando este notebook no Google Colab, descomente a célula abaixo para realizar a autenticação da sua sessão de notebook com a Google Cloud Esse passo é importante **para utilização no Colab** para garantir que as chamadas a APIs de Google Cloud funcionem sem problemas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "NyKGtVQjgx13",
    "tags": []
   },
   "outputs": [],
   "source": [
    "# import sys\n",
    "\n",
    "# # Additional authentication is required for Google Colab\n",
    "# if \"google.colab\" in sys.modules:\n",
    "#     # Authenticate user to Google Cloud\n",
    "#     from google.colab import auth\n",
    "\n",
    "#     auth.authenticate_user()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "DF4l8DTdWgPY"
   },
   "source": [
    "### **Somente para uso no Colab - defina o projeto Google Cloud a ser utilizado** \n",
    "\n",
    "Caso você esteja executando este notebook no Google Colab, descomente a célula abaixo para definir qual projeto Google Cloud será utilizado pelo Colab na execução deste notebook. Senão, siga para as próximas instruções."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Nqwi-5ufWp_B",
    "tags": []
   },
   "outputs": [],
   "source": [
    "# if \"google.colab\" in sys.modules:\n",
    "#     # Define project information\n",
    "#     PROJECT_ID = \"[your-project-id]\"  # @param {type:\"string\"}\n",
    "#     LOCATION = \"us-central1\"  # @param {type:\"string\"}\n",
    "\n",
    "#     # Initialize Vertex AI\n",
    "#     import vertexai\n",
    "\n",
    "#     vertexai.init(project=PROJECT_ID, location=LOCATION)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "jXHfaVS66_01"
   },
   "source": [
    "### Importe as bibliotecas necessárias"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "lslYAvw37JGQ",
    "tags": []
   },
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '3' \n",
    "\n",
    "import warnings\n",
    "warnings.simplefilter(\"ignore\", UserWarning)\n",
    "\n",
    "from vertexai.preview.generative_models import (\n",
    "    GenerationConfig,\n",
    "    GenerativeModel,\n",
    "    Image,\n",
    "    Part,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "4437b7608c8e"
   },
   "source": [
    "## Importe o modelo `Gemini Pro`\n",
    "\n",
    "O Gemini Pro (`gemini-pro`) ajuda na realização de tarefas utilizando linguagem natural, chats multiturno de texto e código e para a geração de código."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "2998506fe6d1",
    "tags": []
   },
   "outputs": [],
   "source": [
    "model = GenerativeModel(\"gemini-pro\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "AIl7R_jBUsaC"
   },
   "source": [
    "### Gere textos a partir de prompts de texto\n",
    "\n",
    "Envie um prompt de texto para o modelo. O modelo Gemini Pro (`gemini-pro`) fornece um mecanismo de resposta de streaming. Com esta abordagem, você não precisa esperar pela resposta completa; você pode começar a processar fragmentos assim que estiverem acessíveis.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "eAo-UsfZECGF",
    "tags": []
   },
   "outputs": [],
   "source": [
    "responses = model.generate_content(\"Por que o céu é azul?\", stream=True)\n",
    "\n",
    "for response in responses:\n",
    "    print(response.text, end=\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Us8idXnVyQ97"
   },
   "source": [
    "#### Experimente seus próprios prompts\n",
    "\n",
    "- Quais são os maiores desafios que o setor de saúde enfrenta?\n",
    "- Quais são os últimos desenvolvimentos na indústria automotiva?\n",
    "- Quais são as maiores oportunidades no setor de varejo?\n",
    "- (Tente suas próprias instruções!)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "MmAZQW1GyQ97",
    "tags": []
   },
   "outputs": [],
   "source": [
    "prompt = \"\"\"Crie uma lista numerada de 10 itens. Cada item da lista deve ser uma tendência na indústria de tecnologia.\n",
    "\n",
    "Cada tendência deve ter menos de 5 palavras.\"\"\" # tente seu próprio prompt\n",
    "\n",
    "responses = model.generate_content(prompt, stream=True)\n",
    "\n",
    "for response in responses:\n",
    "    print(response.text, end=\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "tDK4XLdz3Oqv"
   },
   "source": [
    "#### Parâmetros do modelo\n",
    "\n",
    "Cada prompt enviado ao modelo inclui valores de parâmetros que controlam como o modelo gera uma resposta. O modelo pode gerar resultados diferentes para valores de parâmetros diferentes. Você pode experimentar diferentes parâmetros do modelo para ver como os resultados mudam.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "s_2ann-F3WTo",
    "tags": []
   },
   "outputs": [],
   "source": [
    "generation_config = GenerationConfig(\n",
    "    temperature=0.9, # altere esta variável para testar temperaturas diferentes (entre 0 e 1.0)\n",
    "    top_p=1.0, # altere esta variável para testar top_p diferentes (entre 0.1 e 1.0)\n",
    "    top_k=32, # altere esta variável para testar top_k diferentes (entre 1 e 40)\n",
    "    candidate_count=1,\n",
    "    max_output_tokens=8192, # altere esta variável para testar diferentes tamanhos de respostas (entre 1 e 8192 para o Gemini-Pro)\n",
    ")\n",
    "\n",
    "responses = model.generate_content(\n",
    "    \"Por que o céu é azul?\",\n",
    "    generation_config=generation_config,\n",
    "    stream=True,\n",
    ")\n",
    "\n",
    "for response in responses:\n",
    "    print(response.text, end=\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ga0xM9z9fAnR"
   },
   "source": [
    "### Teste os prompts de chat\n",
    "\n",
    "O modelo Gemini Pro oferece suporte a chats com vários turnos e é ideal para tarefas de texto que exigem interações de ida e volta. Os exemplos a seguir mostram como o modelo responde durante uma conversa multiturnos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "SFbGVflTfBBk",
    "tags": []
   },
   "outputs": [],
   "source": [
    "chat = model.start_chat()\n",
    "\n",
    "prompt = \"\"\"Meu nome é Luciano. Você é meu assistente pessoal. Meus filmes favoritos são Senhor dos Anéis e Hobbit.\n",
    "\n",
    "Sugira outro filme que eu possa gostar.\n",
    "\"\"\"\n",
    "\n",
    "responses = chat.send_message(prompt, stream=True)\n",
    "\n",
    "for response in responses:\n",
    "    print(response.text, end=\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ZP_z_Oh1J4nk"
   },
   "source": [
    "Este prompt de acompanhamento mostra como o modelo responde com base no prompt anterior:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "OCq7JNBKJrI8",
    "tags": []
   },
   "outputs": [],
   "source": [
    "prompt = \"O que estes filmes tem em comum com os filmes que eu gosto?\"\n",
    "\n",
    "responses = chat.send_message(prompt, stream=True)\n",
    "\n",
    "for response in responses:\n",
    "    print(response.text, end=\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Você também pode ter acesso ao histórico do chat:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "print(chat.history)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "OK6TsnYghrQk"
   },
   "source": [
    "## Importe o modelo Gemini Pro Vision\n",
    "\n",
    "Gemini Pro Vision (`gemini-pro-vision`) é um modelo multimodal que suporta prompts multimodais. Você pode incluir texto, imagem(s) e vídeo em suas solicitações de prompt e obter respostas em texto ou código."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "lRyTw2iPhEXG",
    "tags": []
   },
   "outputs": [],
   "source": [
    "multimodal_model = GenerativeModel(\"gemini-pro-vision\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "lwvfMDEDVyKI"
   },
   "source": [
    "### Defina algumas funções auxiliares\n",
    "\n",
    "Defina funções auxiliares para carregar e exibir imagens."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "NQS13DI6Pjp6",
    "tags": []
   },
   "outputs": [],
   "source": [
    "import http.client\n",
    "import typing\n",
    "import urllib.request\n",
    "\n",
    "import IPython.display\n",
    "from PIL import Image as PIL_Image\n",
    "from PIL import ImageOps as PIL_ImageOps\n",
    "\n",
    "\n",
    "def display_images(\n",
    "    images: typing.Iterable[Image],\n",
    "    max_width: int = 600,\n",
    "    max_height: int = 350,\n",
    ") -> None:\n",
    "    for image in images:\n",
    "        pil_image = typing.cast(PIL_Image.Image, image._pil_image)\n",
    "        if pil_image.mode != \"RGB\":\n",
    "            # RGB is supported by all Jupyter environments (e.g. RGBA is not yet)\n",
    "            pil_image = pil_image.convert(\"RGB\")\n",
    "        image_width, image_height = pil_image.size\n",
    "        if max_width < image_width or max_height < image_height:\n",
    "            # Resize to display a smaller notebook image\n",
    "            pil_image = PIL_ImageOps.contain(pil_image, (max_width, max_height))\n",
    "        IPython.display.display(pil_image)\n",
    "\n",
    "\n",
    "def get_image_bytes_from_url(image_url: str) -> bytes:\n",
    "    with urllib.request.urlopen(image_url) as response:\n",
    "        response = typing.cast(http.client.HTTPResponse, response)\n",
    "        image_bytes = response.read()\n",
    "    return image_bytes\n",
    "\n",
    "\n",
    "def load_image_from_url(image_url: str) -> Image:\n",
    "    image_bytes = get_image_bytes_from_url(image_url)\n",
    "    return Image.from_bytes(image_bytes)\n",
    "\n",
    "def get_url_from_gcs(gcs_uri: str) -> str:\n",
    "    # converts gcs uri to url for image display.\n",
    "    url = \"https://storage.googleapis.com/\" + gcs_uri.replace(\"gs://\", \"\").replace(\" \", \"%20\")\n",
    "    return url\n",
    "\n",
    "def print_multimodal_prompt(contents: list):\n",
    "    for content in contents:\n",
    "        if isinstance(content, Image):\n",
    "            display_images([content])\n",
    "        elif isinstance(content, Part):\n",
    "            url = get_url_from_gcs(content.file_data.file_uri)\n",
    "            IPython.display.display(load_image_from_url(url))\n",
    "        else:\n",
    "            print(content)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Wy75sLb-yjNn"
   },
   "source": [
    "### Gere texto a partir de imagens locais\n",
    "\n",
    "Use o método `Image.load_from_file` para carregar um arquivo local como a imagem para a qual gerar texto."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "KzqjpEiryjNo",
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Download an image from Google Cloud Storage\n",
    "! gsutil cp \"gs://cloud-samples-data/generative-ai/image/320px-Felis_catus-cat_on_snow.jpg\" ./image.jpg\n",
    "\n",
    "# Load from local file\n",
    "image = Image.load_from_file(\"image.jpg\")\n",
    "\n",
    "# Prepare contents\n",
    "prompt = \"Descreva esta imagem\"\n",
    "contents = [image, prompt]\n",
    "\n",
    "responses = multimodal_model.generate_content(contents, stream=True)\n",
    "\n",
    "print(\"-------Prompt--------\")\n",
    "print_multimodal_prompt(contents)\n",
    "\n",
    "print(\"\\n-------Resposta--------\")\n",
    "for response in responses:\n",
    "    print(response.text, end=\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Gere texto a partir de texto e imagens"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "GJvME8gV2nyk"
   },
   "source": [
    "#### Imagens com URIs do Cloud Storage\n",
    "\n",
    "Se suas imagens estiverem armazenadas no [Cloud Storage](https://cloud.google.com/storage/docs), você poderá especificar o URI do Cloud Storage da imagem para incluir no prompt. Você também deve especificar o campo `mime_type`. Os tipos MIME suportados para imagens incluem `image/png` e `image/jpeg`.\n",
    "\n",
    "Observe que o URI (não deve ser confundido com URL) de um objeto do Cloud Storage deve sempre começar com `gs://`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Load image from Cloud Storage URI\n",
    "gcs_uri = \"gs://cloud-samples-data/generative-ai/image/boats.jpeg\"\n",
    "\n",
    "# Prepare contents\n",
    "image = Part.from_uri(gcs_uri, mime_type=\"image/jpeg\")\n",
    "prompt = \"Descreva esta cena\"\n",
    "contents = [image, prompt]\n",
    "\n",
    "responses = multimodal_model.generate_content(contents, stream=True)\n",
    "\n",
    "print(\"-------Prompt--------\")\n",
    "print_multimodal_prompt(contents)\n",
    "\n",
    "print(\"\\n-------Resposta--------\")\n",
    "for response in responses:\n",
    "    print(response.text, end=\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Imagens com links diretos\n",
    "\n",
    "Você também pode usar links diretos para imagens, conforme mostrado abaixo. A função auxiliar `load_image_from_url()` (que foi declarada anteriormente) converte a imagem em bytes e a retorna como um objeto Image que pode ser enviado ao `Gemini Pro Vision` junto com o prompt de texto."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Load image from Cloud Storage URI\n",
    "image_url = (\n",
    "    \"https://storage.googleapis.com/cloud-samples-data/generative-ai/image/boats.jpeg\"\n",
    ")\n",
    "image = load_image_from_url(image_url) # convert to bytes\n",
    "\n",
    "# Prepare contents\n",
    "prompt = \"Descreva esta cena\"\n",
    "contents = [image, prompt]\n",
    "\n",
    "responses = multimodal_model.generate_content(contents, stream=True)\n",
    "\n",
    "print(\"-------Prompt--------\")\n",
    "print_multimodal_prompt(contents)\n",
    "\n",
    "print(\"\\n-------Resposta--------\")\n",
    "for response in responses:\n",
    "    print(response.text, end=\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Combinando várias imagens e solicitações de texto em um prompt *few-shot*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Você pode enviar mais de uma imagem por vez e também colocá-las em qualquer lugar ao lado do prompt de texto.\n",
    "\n",
    "No exemplo abaixo, a solicitação de poucas fotos é executada para que o `Gemini Pro Vision` retorne a cidade e o ponto de referência em um formato JSON específico."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "VfU7Qlz1hAEA",
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Load images from Cloud Storage URI\n",
    "image1_url = \"https://storage.googleapis.com/github-repo/img/gemini/intro/landmark1.jpg\"\n",
    "image2_url = \"https://storage.googleapis.com/github-repo/img/gemini/intro/landmark2.jpg\"\n",
    "image3_url = \"https://storage.googleapis.com/github-repo/img/gemini/intro/landmark3.jpg\"\n",
    "image1 = load_image_from_url(image1_url)\n",
    "image2 = load_image_from_url(image2_url)\n",
    "image3 = load_image_from_url(image3_url)\n",
    "\n",
    "# Prepare prompts\n",
    "prompt1 = \"\"\"{\"cidade\": \"Londres\", \"ponto_turistico:\", \"Big Ben\"}\"\"\"\n",
    "prompt2 = \"\"\"{\"cidade\": \"Paris\", \"ponto_turistico:\", \"Torre Eiffel\"}\"\"\"\n",
    "\n",
    "# Prepare contents\n",
    "contents = [image1, prompt1, image2, prompt2, image3]\n",
    "\n",
    "responses = multimodal_model.generate_content(contents, stream=True)\n",
    "\n",
    "print(\"-------Prompt--------\")\n",
    "print_multimodal_prompt(contents)\n",
    "\n",
    "print(\"\\n-------Resposta--------\")\n",
    "for response in responses:\n",
    "    print(response.text, end=\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "vyjpi1fB7mgj"
   },
   "source": [
    "### Gere texto a partir de um arquivo de vídeo\n",
    "\n",
    "Especifique o URI do Cloud Storage de um vídeo a ser incluído no prompt. Você também deve especificar o campo `mime_type`. O tipo MIME suportado para vídeo inclui `video/mp4`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "file_path = \"github-repo/img/gemini/multimodality_usecases_overview/pixel8.mp4\"\n",
    "video_uri = f\"gs://{file_path}\"\n",
    "video_url = f\"https://storage.googleapis.com/{file_path}\"\n",
    "\n",
    "IPython.display.Video(video_url, width=450)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "VXX1jLXq7ojB",
    "tags": []
   },
   "outputs": [],
   "source": [
    "prompt = \"\"\"\n",
    "Responda às seguintes perguntas usando apenas o vídeo:\n",
    "Qual é a profissão da pessoa principal do vídeo?\n",
    "Quais são as principais funcionalidades do telefone são apresentadas neste vídeo?\n",
    "Em que cidade isso foi gravado?\n",
    "Forneça a resposta JSON.\n",
    "\"\"\"\n",
    "\n",
    "video = Part.from_uri(video_uri, mime_type=\"video/mp4\")\n",
    "contents = [prompt, video]\n",
    "\n",
    "responses = multimodal_model.generate_content(contents, stream=True)\n",
    "\n",
    "for response in responses:\n",
    "    print(response.text, end=\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "provenance": [],
   "toc_visible": true
  },
  "environment": {
   "kernel": "python3",
   "name": "tf2-gpu.2-11.m109",
   "type": "gcloud",
   "uri": "gcr.io/deeplearning-platform-release/tf2-gpu.2-11:m109"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
