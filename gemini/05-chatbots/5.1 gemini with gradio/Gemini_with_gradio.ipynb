{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ijGzTHJJUCPY"
   },
   "outputs": [],
   "source": [
    "# Copyright 2023 Google LLC\n",
    "#\n",
    "# Licensed under the Apache License, Version 2.0 (the \"License\");\n",
    "# you may not use this file except in compliance with the License.\n",
    "# You may obtain a copy of the License at\n",
    "#\n",
    "#     https://www.apache.org/licenses/LICENSE-2.0\n",
    "#\n",
    "# Unless required by applicable law or agreed to in writing, software\n",
    "# distributed under the License is distributed on an \"AS IS\" BASIS,\n",
    "# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
    "# See the License for the specific language governing permissions and\n",
    "# limitations under the License."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "VEqbX8OhE8y9"
   },
   "source": [
    "# Construindo um chatbot com Gemini e gradio\n",
    "\n",
    "<table align=\"left\">\n",
    "  <td style=\"text-align: center\">\n",
    "    <a href=\"https://colab.research.google.com/github/GoogleCloudPlatform/generative-ai/blob/main/gemini/getting-started/intro_gemini_python.ipynb\">\n",
    "      <img src=\"https://cloud.google.com/ml-engine/images/colab-logo-32px.png\" alt=\"Google Colaboratory logo\"><br> Executar no Colab\n",
    "    </a>\n",
    "  </td>\n",
    "  <td style=\"text-align: center\">\n",
    "    <a href=\"https://github.com/GoogleCloudPlatform/generative-ai/blob/main/gemini/getting-started/intro_gemini_python.ipynb\">\n",
    "      <img src=\"https://cloud.google.com/ml-engine/images/github-logo-32px.png\" alt=\"GitHub logo\"><br> Ver no GitHub\n",
    "    </a>\n",
    "  </td>\n",
    "  <td style=\"text-align: center\">\n",
    "    <a href=\"https://console.cloud.google.com/vertex-ai/workbench/deploy-notebook?download_url=https://raw.githubusercontent.com/GoogleCloudPlatform/generative-ai/blob/main/gemini/getting-started/intro_gemini_python.ipynb\">\n",
    "      <img src=\"https://lh3.googleusercontent.com/UiNooY4LUgW_oTvpsNhPpQzsstV5W8F7rYgxgGBD85cWJoLmrOzhVs_ksK_vgx40SHs7jCqkTkCk=e14-rj-sc0xffffff-h130-w32\" alt=\"Vertex AI logo\"><br> Abrir no Workbench da Vertex AI\n",
    "    </a>\n",
    "  </td>\n",
    "</table>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "CkHPv2myT2cx"
   },
   "source": [
    "## Vis√£o Geral\n",
    "\n",
    "### Gemini\n",
    "\n",
    "Gemini √© uma fam√≠lia de modelos generativos de IA desenvolvidos pelo Google DeepMind e projetados para casos de uso multimodais. A API Gemini d√° acesso aos modelos Gemini Pro Vision e Gemini Pro.\n",
    "\n",
    "### API Vertex AI Gemini\n",
    "\n",
    "A API Vertex AI Gemini fornece uma interface unificada para interagir com modelos Gemini. Atualmente existem dois modelos dispon√≠veis na API Gemini:\n",
    "\n",
    "- **Modelo Gemini Pro** (`gemini-pro`): Projetado para lidar com tarefas de linguagem natural, bate-papo multivoltas de texto e c√≥digo e gera√ß√£o de c√≥digo.\n",
    "- **Modelo Gemini Pro Vision** (`gemini-pro-vision`): Suporta prompts multimodais. Voc√™ pode incluir texto, imagens e v√≠deo em suas solicita√ß√µes de prompt e obter respostas em texto ou c√≥digo.\n",
    "\n",
    "Voc√™ pode interagir com a API Gemini usando os seguintes m√©todos:\n",
    "\n",
    "- Use o [Vertex AI Studio](https://cloud.google.com/generative-ai-studio) para testes r√°pidos e gera√ß√£o de comandos\n",
    "- Use o SDK da Vertex AI\n",
    "\n",
    "### gradio\n",
    "\n",
    "Gradio √© uma biblioteca Python que permite criar rapidamente aplicativos web personaliz√°veis. Neste laborat√≥rio, vamos utilizar a biblioteca para criar um chatbot que utiliza as capacidades multimodais do modelo Gemini. Maiores detalhes sobre sobre o Gradio na [p√°gina oficial do projeto](https://www.gradio.app).\n",
    "\n",
    "Este notebook se concentra no uso do **Vertex AI SDK para Python** para chamar a API Vertex AI Gemini.\n",
    "\n",
    "Para obter mais informa√ß√µes, consulte a documenta√ß√£o [IA Generativa na Vertex AI](https://cloud.google.com/vertex-ai/docs/generative-ai/learn/overview)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "DrkcqHrrwMAo"
   },
   "source": [
    "### Objetivos\n",
    "\n",
    "Neste tutorial, voc√™ aprender√° como usar a API Vertex AI Gemini com o SDK Vertex AI para Python para interagir com os modelos Gemini Pro (`gemini-pro`) e o Gemini Pro Vision (`gemini-pro-vision`).\n",
    "\n",
    "Voc√™ concluir√° as seguintes tarefas:\n",
    "\n",
    "- Instalar o SDK da Vertex AI para Python\n",
    "- Usar a API Vertex AI Gemini para interagir com cada modelo\n",
    "   - Modelo Gemini Pro (`gemini-pro`):\n",
    "     - Gere texto a partir de prompts de texto\n",
    "     - Explore v√°rios recursos e op√ß√µes de configura√ß√£o\n",
    "   - Modelo Gemini Pro Vision (`gemini-pro-vision`):\n",
    "     - Gere texto a partir de imagens e prompts de texto\n",
    "     - Gere texto a partir de prompts de v√≠deo e texto\n",
    "- Criar uma aplica√ß√£o com Gradio\n",
    "   - Interagir com o modelo Gemini via a aplica√ß√£o Gradio"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "C9nEPojogw-g"
   },
   "source": [
    "### Custos\n",
    "\n",
    "Este tutorial usa os seguintes componentes de Google Cloud que podem gerar custos em sua fatura:\n",
    "\n",
    "- Artifacts Registry\n",
    "- Cloud Build\n",
    "- Cloud Run\n",
    "- Vertex AI\n",
    "\n",
    "Saiba mais sobre os servi√ßos utilizando a [calculadora de pre√ßos](https://cloud.google.com/products/calculator/) para gerar uma estimativa de custo com base no uso projetado."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "r11Gu7qNgx1p"
   },
   "source": [
    "## Primeiros passos"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "No17Cw5hgx12"
   },
   "source": [
    "### Instale a SDK da Vertex AI\n",
    "**Importante:** s√≥ descomente a linha abaixo se voc√™ **n√£o estiver** executando este laborat√≥rio no Qwiklabs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "tFy3H3aPgx12",
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "# ! pip3 install --upgrade --user google-cloud-aiplatform"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "j7UyNVSiyQ96",
    "tags": []
   },
   "source": [
    "### **Reinicie o kernel do seu jupyter notebook** \n",
    "\n",
    "Como a instala√ß√£o est√° sendo realizada com a op√ß√£o `--user` √© necess√°rio reiniciar o kernel para que os novos m√≥dulos se tornem acess√≠veis.\n",
    "\n",
    "**Importante:** s√≥ descomente a linha abaixo se voc√™ **n√£o estiver** executando este laborat√≥rio no Qwiklabs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "YmY9HVVGSBW5",
    "tags": []
   },
   "outputs": [],
   "source": [
    "# import IPython\n",
    "\n",
    "# app = IPython.Application.instance()\n",
    "# app.kernel.do_shutdown(True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-warning\">\n",
    "<b>‚ö†Ô∏è O kernel do notebook est√° sendo reiniciado. Por favor aguarde este processo ser finalizado antes de continuar com os pr√≥ximos passos. ‚ö†Ô∏è</b>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "dmWOrTJ3gx13"
   },
   "source": [
    "### **Somente para uso no Colab - Autentique o seu ambiente de notebook** \n",
    "\n",
    "Caso voc√™ esteja executando este notebook no Google Colab, descomente a c√©lula abaixo para realizar a autentica√ß√£o da sua sess√£o de notebook com a Google Cloud Esse passo √© importante **para utiliza√ß√£o no Colab** para garantir que as chamadas a APIs de Google Cloud funcionem sem problemas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "NyKGtVQjgx13",
    "tags": []
   },
   "outputs": [],
   "source": [
    "# import sys\n",
    "\n",
    "# # Additional authentication is required for Google Colab\n",
    "# if \"google.colab\" in sys.modules:\n",
    "#     # Authenticate user to Google Cloud\n",
    "#     from google.colab import auth\n",
    "\n",
    "#     auth.authenticate_user()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "DF4l8DTdWgPY"
   },
   "source": [
    "### **Somente para uso no Colab - defina o projeto Google Cloud a ser utilizado** \n",
    "\n",
    "Caso voc√™ esteja executando este notebook no Google Colab, descomente a c√©lula abaixo para definir qual projeto Google Cloud ser√° utilizado pelo Colab na execu√ß√£o deste notebook. Sen√£o, siga para as pr√≥ximas instru√ß√µes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Nqwi-5ufWp_B",
    "tags": []
   },
   "outputs": [],
   "source": [
    "# if \"google.colab\" in sys.modules:\n",
    "#     # Define project information\n",
    "#     PROJECT_ID = \"[your-project-id]\"  # @param {type:\"string\"}\n",
    "#     LOCATION = \"us-central1\"  # @param {type:\"string\"}\n",
    "\n",
    "#     # Initialize Vertex AI\n",
    "#     import vertexai\n",
    "\n",
    "#     vertexai.init(project=PROJECT_ID, location=LOCATION)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Inicie os servi√ßos necess√°rios"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "!gcloud services enable cloudbuild.googleapis.com\n",
    "!gcloud services enable artifactregistry.googleapis.com\n",
    "!gcloud services enable run.googleapis.com"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Configure a CLI da Google Cloud (`gcloud`)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Configura√ß√£o do PROJECT_ID"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "shell_output = ! gcloud config list --format 'value(core.project)' 2>/dev/null\n",
    "PROJECT_ID = shell_output[0]\n",
    "print(\"Project ID:\", PROJECT_ID)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Configura√ß√£o de regi√£o a ser utilizada"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "REGION = \"us-central1\"\n",
    "\n",
    "if REGION == \"[your-region]\":\n",
    "    REGION = \"us-central1\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Criando o servi√ßo que utilizaremos com o Gradio\n",
    "\n",
    "**Importante:** Atualize as vari√°veis `PROJECT_ID` e `LOCATION` antes de continuar. Os valores que voc√™ precisa colocar s√£o os abaixo:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "print(f\"PROJECT_ID: {PROJECT_ID}\")\n",
    "print(f\"REGION: {REGION}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "%%writefile main.py\n",
    "\n",
    "import os\n",
    "import time\n",
    "import base64\n",
    "import gradio as gr\n",
    "\n",
    "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '3' \n",
    "\n",
    "import warnings\n",
    "warnings.simplefilter(\"ignore\", UserWarning)\n",
    "\n",
    "import vertexai\n",
    "from vertexai.generative_models import (\n",
    "    GenerativeModel,\n",
    "    Image\n",
    ")\n",
    "\n",
    "# cabe√ßalho da p√°gina\n",
    "TITLE = \"\"\"<h1 align=\"center\">Chatbot com Gemini ü§ñ</h1>\"\"\"\n",
    "SUBTITLE = \"\"\"<h2 align=\"center\">Prot√≥tipo de um chatbot multimodal com Gemini e Gradio</h2>\"\"\"\n",
    "\n",
    "# variaveis de projeto e regiao\n",
    "PROJECT_ID=\"[nome do seu projeto]\" # TODO: atualize para o seu PROJECT_ID\n",
    "LOCATION=\"[regi√£o a ser utilizado]\" # TODO: atualize para o seu REGION\n",
    "\n",
    "# inicializando a SDK da Vertex AI\n",
    "vertexai.init(project=PROJECT_ID, location=LOCATION)\n",
    "\n",
    "# instanciando os clientes de Gemini e Gemini-Pro\n",
    "model = GenerativeModel(\"gemini-1.0-pro\")\n",
    "multimodal_model = GenerativeModel(\"gemini-1.0-pro-vision\")\n",
    "\n",
    "\n",
    "# converte imagens para formato base64\n",
    "def image_to_base64(image_path):\n",
    "    with open(image_path, 'rb') as img:\n",
    "        encoded_string = base64.b64encode(img.read())\n",
    "    return encoded_string.decode('utf-8')\n",
    "\n",
    "\n",
    "# mostra a entrada do usuario no historico do chatbot\n",
    "def query_message(history,txt,img):\n",
    "    if not img:\n",
    "        history += [(txt,None)]\n",
    "        return history\n",
    "    print(\"imagem recebida:\")\n",
    "    print(img)\n",
    "    base64 = image_to_base64(img)\n",
    "    data_url = f\"data:image/jpeg;base64,{base64}\"\n",
    "    history += [(f\"{txt} ![]({data_url})\", None)]\n",
    "    return history\n",
    "    \n",
    "# usa o input do usuario, interage com o Gemini, gera resposta \n",
    "# e mostra no historico do chatbot\n",
    "def llm_response(history,text,img):\n",
    "    if not img:\n",
    "        response = model.generate_content(text)\n",
    "        history += [(None,response.text)]\n",
    "        return history\n",
    "    else:\n",
    "        print(\"imagem no llm_response:\")\n",
    "        print(img)\n",
    "        try:\n",
    "            img = Image.load_from_file(img)\n",
    "            response = multimodal_model.generate_content([text,img])\n",
    "            print(\"resposta da chamada de API:\")\n",
    "            print(response.text)\n",
    "            history += [(None,response.text)]\n",
    "            return history\n",
    "        except Exception as e:\n",
    "            print(\"deu erro na llm_response\")\n",
    "            print(str(e))\n",
    "            return history\n",
    "    \n",
    "    \n",
    "# interface do gradio\n",
    "print(\"Iniciando a constru√ß√£o da app gradio...\")\n",
    "with gr.Blocks() as app:\n",
    "    gr.HTML(TITLE)\n",
    "    gr.HTML(SUBTITLE)\n",
    "    with gr.Row():\n",
    "        image_box = gr.Image(type=\"filepath\")\n",
    "        chatbot = gr.Chatbot(\n",
    "            scale = 2,\n",
    "            height=750\n",
    "        )\n",
    "        \n",
    "    text_box = gr.Textbox(\n",
    "            placeholder=\"Digite sua mensagem e tecle enter ou fa√ßa o upload de uma imagem\",\n",
    "            container=False,\n",
    "        )\n",
    "\n",
    "    btn = gr.Button(\"Enviar\")\n",
    "    clicked = btn.click(query_message,\n",
    "                        [chatbot,text_box,image_box],\n",
    "                        chatbot\n",
    "                        ).then(llm_response,\n",
    "                                [chatbot,text_box,image_box],\n",
    "                                chatbot\n",
    "                                )\n",
    "\n",
    "app.queue()\n",
    "app.launch(server_name=\"0.0.0.0\", server_port=7860)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "4437b7608c8e"
   },
   "source": [
    "### Definindo o `Dockerfile` que utilizaremos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "2998506fe6d1",
    "tags": []
   },
   "outputs": [],
   "source": [
    "%%writefile Dockerfile\n",
    "\n",
    "FROM python:3.8\n",
    "\n",
    "EXPOSE 8080\n",
    "WORKDIR /app\n",
    "\n",
    "COPY . ./\n",
    "\n",
    "EXPOSE 7860\n",
    "\n",
    "RUN pip install -r requirements.txt\n",
    "\n",
    "ENTRYPOINT [\"python\", \"main.py\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "AIl7R_jBUsaC"
   },
   "source": [
    "### Criando a imagem de container que utilizaremos no laborat√≥rio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "!gcloud artifacts repositories create gemini-gradio-repo --repository-format=docker --location=$REGION\n",
    "!gcloud builds submit --tag us-central1-docker.pkg.dev/$PROJECT_ID/gemini-gradio-repo/gemini-gradio-app"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Criando a aplica√ß√£o no Cloud Run\n",
    "\n",
    "Basicamente o que est√° sendo feito aqui √©:\n",
    "- Criando um servi√ßo no Cloud Run chamado `gemini-gradio-app`\n",
    "- Utilizar√° a imagem de container que foi criada anteriormente: `us-central1-docker.pkg.dev/<PROJECT_ID>/gemini-gradio-repo/gemini-gradio-app`\n",
    "- Permitir√° acesso n√£o autenticado com a cl√°usula `--allow-unauthenticated`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "!gcloud run deploy gemini-gradio-app --port 7860 --image us-central1-docker.pkg.dev/$PROJECT_ID/gemini-gradio-repo/gemini-gradio-app --allow-unauthenticated --region=us-central1 --platform=managed"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Acessando o seu servi√ßo\n",
    "\n",
    "Ao final da execu√ß√£o da c√©lula anterior, vai haver uma informa√ß√£o como abaixo:\n",
    "\n",
    "`Service URL: https://gemini-gradio-app-XXX-uc.a.run.app`\n",
    "\n",
    "Copie esta URL em uma nova aba do navegador e acesse a sua aplica√ß√£o Gradio com Gemini."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "provenance": [],
   "toc_visible": true
  },
  "environment": {
   "kernel": "python3",
   "name": "tf2-cpu.2-11.m117",
   "type": "gcloud",
   "uri": "us-docker.pkg.dev/deeplearning-platform-release/gcr.io/tf2-cpu.2-11:m117"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
