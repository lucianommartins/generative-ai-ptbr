{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ijGzTHJJUCPY"
   },
   "outputs": [],
   "source": [
    "# Copyright 2023 Google LLC\n",
    "#\n",
    "# Licensed under the Apache License, Version 2.0 (the \"License\");\n",
    "# you may not use this file except in compliance with the License.\n",
    "# You may obtain a copy of the License at\n",
    "#\n",
    "#     https://www.apache.org/licenses/LICENSE-2.0\n",
    "#\n",
    "# Unless required by applicable law or agreed to in writing, software\n",
    "# distributed under the License is distributed on an \"AS IS\" BASIS,\n",
    "# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
    "# See the License for the specific language governing permissions and\n",
    "# limitations under the License."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "VEqbX8OhE8y9"
   },
   "source": [
    "# Criando código GoogleSQL para o BigQuery com GenAI\n",
    "\n",
    "<table align=\"left\">\n",
    "  <td>\n",
    "    <a href=\"https://colab.research.google.com/github/GoogleCloudPlatform/generative-ai/blob/main/language/intro_palm_api.ipynb\">\n",
    "      <img src=\"https://cloud.google.com/ml-engine/images/colab-logo-32px.png\" alt=\"Colab logo\"> Execute no Colab\n",
    "    </a>\n",
    "  </td>\n",
    "  <td>\n",
    "    <a href=\"https://github.com/GoogleCloudPlatform/generative-ai/blob/main/language/intro_palm_api.ipynb\">\n",
    "      <img src=\"https://cloud.google.com/ml-engine/images/github-logo-32px.png\" alt=\"GitHub logo\">\n",
    "      Veja no GitHub\n",
    "    </a>\n",
    "  </td>\n",
    "  <td>\n",
    "    <a href=\"https://console.cloud.google.com/vertex-ai/workbench/deploy-notebook?download_url=https://raw.githubusercontent.com/GoogleCloudPlatform/generative-ai/blob/main/language/intro_palm_api.ipynb\">\n",
    "      <img src=\"https://lh3.googleusercontent.com/UiNooY4LUgW_oTvpsNhPpQzsstV5W8F7rYgxgGBD85cWJoLmrOzhVs_ksK_vgx40SHs7jCqkTkCk=e14-rj-sc0xffffff-h130-w32\" alt=\"Vertex AI logo\">\n",
    "      Execute no Vertex AI Workbench\n",
    "    </a>\n",
    "  </td>\n",
    "</table>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "VK1Q5ZYdVL4Y"
   },
   "source": [
    "## Visão geral\n",
    "\n",
    "Segmentação de clientes é o processo de agrupar clientes base em características similares para ajudar no engajamento de uma marca ou de um produto com sua audiência. Isso pode ser feito usando uma variedade de fatores, como dados demográficos e comportamentais. Mecanismos de *machine learning* podem ser usados para automatizar o processo de segmentação de clientes, tornando-o mais eficiente e eficaz.\n",
    "\n",
    "### BigQuery\n",
    "\n",
    "O [BigQuery](https://cloud.google.com/bigquery/). é o serviço de base de dados gerenciado, serverless e escalável disponível na Google Cloud. O BigQuery permite gerenciar e analisar dados com recursos integrados, como *machine learning*, análise geoespacial e *business intelligence*. Para maiores detalhes, visite a [documentação oficial](https://cloud.google.com/bigquery/docs) do BigQuery.\n",
    "\n",
    "### Vertex AI PaLM API\n",
    "A Vertex AI PaLM API, [lançada em 10 de maio de 2023](https://cloud.google.com/vertex-ai/docs/generative-ai/release-notes#may_10_2023), é desenvolvida com [PaLM 2]( https://ai.google/discover/palm2).\n",
    "\n",
    "### Usando a API Vertex AI PaLM\n",
    "\n",
    "Você pode interagir com a API Vertex AI PaLM usando os seguintes métodos:\n",
    "\n",
    "* Use a UI da [Vertex AI Studio](https://cloud.google.com/generative-ai-studio) para testes rápidos e geração de comandos.\n",
    "* Faça chamadas REST no Cloud Shell.\n",
    "* Use o Python SDK em um notebook Jupyter\n",
    "\n",
    "Este notebook se concentra no uso do Python SDK para chamar a Vertex AI PaLM API. Para obter mais informações sobre como usar o Vertex AI Studio sem escrever código, você pode explorar [Introdução às instruções da interface do usuário](https://github.com/GoogleCloudPlatform/generative-ai/blob/main/getting-started/getting_started_ui.md)\n",
    "\n",
    "Para obter mais informações, confira a [documentação sobre suporte de IA generativa para Vertex AI](https://cloud.google.com/vertex-ai/docs/generative-ai/learn/overview)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "RQT500QqVPIb"
   },
   "source": [
    "### Objetivos\n",
    "\n",
    "Neste tutorial, você irá utilizar os serviços de Google Cloud para:\n",
    "\n",
    "* Explorar dados do dataset público ``bigquery-public-data.chicago_crime`\n",
    "* Utilizar as API do GenAI Studio para a geração de código GoogleSQL e entendimento dos dados do dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "1y6_3dTwV2fI"
   },
   "source": [
    "### Custos\n",
    "Este tutorial usa os seguintes componentes de Google Cloud:\n",
    "\n",
    "* Vertex AI Studio\n",
    "* BigQuery\n",
    "\n",
    "Saiba mais sobre possíveis custos envolvidos [preços da Vertex AI](https://cloud.google.com/vertex-ai/pricing),\n",
    "[preços do BigQuery](https://cloud.google.com/bigquery/pricing),\n",
    "e use a [Calculadora de preços](https://cloud.google.com/products/calculator/)\n",
    "para gerar uma estimativa de custo com base no uso projetado."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "6ae098456471"
   },
   "source": [
    "### Segurança de dados\n",
    "**P: O Google usa dados de clientes para melhorar seus modelos de base?**\n",
    "R: Não, o Google não usa dados de clientes para melhorar os modelos de fundação. Os dados do cliente são usados apenas para gerar uma resposta do modelo.\n",
    "\n",
    "**P: Os funcionários do Google veem os dados que envio ao modelo?**\n",
    "R: Não, os funcionários do Google não têm acesso aos dados do cliente e todos os dados são criptografados em trânsito, em uso e em repouso.\n",
    "\n",
    "**P: O Google armazena algum dos dados do cliente que são enviados para o modelo?**\n",
    "R: Não, o Google não armazena dados de clientes. No entanto, o Google pode armazenar em cache temporariamente os dados do cliente durante a solicitação, como pipeline de ajuste de prompt e uso em batch.\n",
    "\n",
    "**P: O Google registra dados?**\n",
    "R: Não, o Google não loga os dados dos clientes. Os logs do lado do sistema ajudam o Google a garantir a integridade e a disponibilidade do sistema."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "fc389a25bf64"
   },
   "source": [
    "### IA Responsável\n",
    "LLMs podem traduzir linguagem, resumir texto, gerar escrita criativa, gerar código, chatbots e assistentes virtuais, além de complementar mecanismos de pesquisa e sistemas de recomendação. Ao mesmo tempo, como uma tecnologia em estágio inicial, seus recursos e usos em evolução podem criar aplicações incorretas, uso indevido e consequências não intencionais ou imprevistas. LLMs podem gerar resultados inesperados, incluindo texto ofensivo, insensível ou incorreto.\n",
    "\n",
    "Além disso, a incrível versatilidade dos LLMs também é o que torna difícil prever exatamente que tipos de saídas não intencionais ou imprevistas eles podem produzir. Dados esses riscos e complexidades, a API PaLM foi projetada com os [AI Principles do Google](https://ai.google/principles/) em mente. No entanto, é importante que os desenvolvedores entendam e testem seus modelos para implantá-los com segurança e responsabilidade. Para ajudar os desenvolvedores, o Vertex AI Studio possui filtragem de conteúdo integrada e a API PaLM possui pontuação de atributo de segurança para ajudar os clientes a testar os filtros de segurança do Google e definir limites de confiança adequados para seu caso de uso e negócios. Consulte a seção [Filtros e atributos de segurança](https://cloud.google.com/vertex-ai/docs/generative-ai/learn/responsible-ai#safety_filters_and_attributes) para saber mais.\n",
    "\n",
    "Quando a API PaLM é integrada ao caso de uso e contexto exclusivos de um cliente, considerações adicionais de IA Responsável e [limitações PaLM](https://cloud.google.com/vertex-ai/docs/generative-ai/learn/responsible-ai #palm_limitations) precisam ser considerados. Incentivamos os clientes a usar *fairness*, interpretabilidade, privacidade e segurança [práticas recomendadas](https://ai.google/responsabilidades/responsible-ai-practices/)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "QDU0XJ1xRDlL"
   },
   "source": [
    "## Primeiros Passos"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "N5afkyDMSBW5"
   },
   "source": [
    "### Instalando os SDK da Vertex AI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "kc4WxYmLSBW5",
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "!pip install google-cloud-aiplatform==1.29.0 --upgrade --user"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Somente Colab:** Descomente a célula a seguir para reiniciar o kernel ou use o botão para reiniciar o kernel."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "YmY9HVVGSBW5"
   },
   "outputs": [],
   "source": [
    "# # Reinicia automaticamente o kernel após as instalações para que seu ambiente possa acessar os novos pacotes\n",
    "# import IPython\n",
    "\n",
    "# app = IPython.Application.instance()\n",
    "# app.kernel.do_shutdown(True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "6Fom0ZkMSBW6"
   },
   "source": [
    "### Autenticando seu ambiente de notebook\n",
    "* Se você estiver usando o **Colab** para executar este notebook, descomente a célula abaixo e continue.\n",
    "* Se você estiver usando o **Vertex AI Workbench**, confira as instruções de configuração [aqui](../setup-env/README.md)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "LCaCx6PLSBW6"
   },
   "outputs": [],
   "source": [
    "# from google.colab import auth\n",
    "# auth.authenticate_user()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "BuQwwRiniVFG"
   },
   "source": [
    "### Importando as bibliotecas necessárias"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Somente Colab:** Descomente a célula a seguir para realizar o processo adequado de inicialização da SDK da Vertex AI.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import vertexai\n",
    "\n",
    "# PROJECT_ID = \"[seu-project-id]\"  # @param {type:\"string\"}\n",
    "# vertexai.init(project=PROJECT_ID, location=\"us-central1\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "4zjV4alsiVql"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '3' \n",
    "\n",
    "import warnings\n",
    "warnings.simplefilter(\"ignore\", UserWarning)\n",
    "\n",
    "import sys\n",
    "import time\n",
    "import pandas as pd\n",
    "from typing import Union\n",
    "from google.cloud import bigquery\n",
    "from vertexai.language_models import TextGenerationModel, CodeGenerationModel"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "_mU6EZEhakVu"
   },
   "source": [
    "## Geração de texto com `code-bison@001`\n",
    "\n",
    "O modelo de geração de texto da API PaLM que você usará neste notebook é `code-bison@001`. Já deixaremos seu objeto instanciado neste Jupyter notebook para uso futuro"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "4437b7608c8e"
   },
   "source": [
    "#### Carregando o modelo `code-bison`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "2998506fe6d1"
   },
   "outputs": [],
   "source": [
    "code_model = CodeGenerationModel.from_pretrained(\"code-bison@001\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preparando as funções necessárias \n",
    "\n",
    "Aqui vamos criar a função `pergunta()` que será utilizada para gerar as solicitações às API do Vertex GenAI Studio:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def codifique(prompt : str , temperature: float = .2) -> str:\n",
    "\n",
    "    parameters = {\n",
    "        \"temperature\": temperature,\n",
    "        \"max_output_tokens\": 256,\n",
    "    }\n",
    "\n",
    "    response = code_model.predict(\n",
    "        prompt,\n",
    "        **parameters,\n",
    "    )\n",
    "    return(response.text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Criação do dataset no BigQuery\n",
    "\n",
    "Para termos uma estrutura pronta no projeto do laboratório para salvar e explorar dados, vamos criar um projeto no BigQuery:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "project_id = !gcloud config list project\n",
    "project_id = project_id[1].split('=')[1].strip()\n",
    "parent = f'projects/' + project_id\n",
    "\n",
    "client = bigquery.Client(project=project_id)\n",
    "dataset_id = f\"{project_id}.geracao_googlesql\"\n",
    "dataset = bigquery.Dataset(dataset_id)\n",
    "dataset.location = \"US\"\n",
    "\n",
    "try:\n",
    "    dataset = client.create_dataset(dataset, timeout=30)\n",
    "    print(\"Dataset criado com sucesso {}.{}\".format(project_id, dataset.dataset_id))\n",
    "except:\n",
    "    print(f\"O dataset {dataset_id} já existe\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Agora utilizando somente linguagem natural, vamos solicitar oa modelo generativo do Vertex GenAI Studio para criar uma query GoogleSQL:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sql = codifique('''Usando a tabela \"`bigquery-public-data.chicago_crime.crime`\"\n",
    "Escreva um GoogleSQL para encontrar os 10 principais números de case_number por location_description\n",
    "onde a parte do ano do campo datetime \"date\" é 2010\n",
    "não anexe \"```\" à resposta, não anexe \"sql\" a resposta\n",
    "não crie ou exclua nenhum dado.\n",
    "não utilizar markdowns e nem comentários.''')\n",
    "sql = sql.split(\"```\")[1].replace('sql\\n', '')\n",
    "print(sql)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Com a query criada pelo modelo generativo, podemos enviar a query diretamente como variável para o cliente da SDK do BigQuery e buscar os resultados:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "query_job = client.query(sql.replace('```', ''))\n",
    "results = query_job.result()\n",
    "\n",
    "list_of_rows = ''\n",
    "for row in results:\n",
    "    list_of_rows += str(row.values()) + '\\n'\n",
    "\n",
    "print(list_of_rows)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "De último podemos fazer uma busca no modelo generativo pela informação gerada pela query (neste caso, qual o local de crime mais comum na cidade de Chicago em 2010):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "generation_model = TextGenerationModel.from_pretrained(\"text-bison@001\")\n",
    "\n",
    "resposta = generation_model.predict(prompt='De forma sucinta, diga que tipo de local aconteceram mais ocorrências em Chicago no ano de 2010?',\n",
    "                                    top_k=20,\n",
    "                                    top_p=0.2,\n",
    "                                    temperature=0)\n",
    "print(resposta.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "name": "intro_palm_api.ipynb",
   "toc_visible": true
  },
  "environment": {
   "kernel": "python3",
   "name": "tf2-gpu.2-11.m109",
   "type": "gcloud",
   "uri": "gcr.io/deeplearning-platform-release/tf2-gpu.2-11:m109"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
