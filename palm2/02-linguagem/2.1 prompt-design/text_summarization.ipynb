{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ur8xi4C7S06n"
   },
   "outputs": [],
   "source": [
    "# Copyright 2023 Google LLC\n",
    "#\n",
    "# Licensed under the Apache License, Version 2.0 (the \"License\");\n",
    "# you may not use this file except in compliance with the License.\n",
    "# You may obtain a copy of the License at\n",
    "#\n",
    "#     https://www.apache.org/licenses/LICENSE-2.0\n",
    "#\n",
    "# Unless required by applicable law or agreed to in writing, software\n",
    "# distributed under the License is distributed on an \"AS IS\" BASIS,\n",
    "# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
    "# See the License for the specific language governing permissions and\n",
    "# limitations under the License."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "JAPoU8Sm5E6e"
   },
   "source": [
    "# Sumariza√ß√£o de textos com Generative AI na Vertex AI\n",
    "\n",
    "<table align=\"left\">\n",
    "  <td>\n",
    "    <a href=\"https://colab.research.google.com/github/GoogleCloudPlatform/generative-ai/blob/main/language/intro_palm_api.ipynb\">\n",
    "      <img src=\"https://cloud.google.com/ml-engine/images/colab-logo-32px.png\" alt=\"Colab logo\"> Execute no Colab\n",
    "    </a>\n",
    "  </td>\n",
    "  <td>\n",
    "    <a href=\"https://github.com/GoogleCloudPlatform/generative-ai/blob/main/language/intro_palm_api.ipynb\">\n",
    "      <img src=\"https://cloud.google.com/ml-engine/images/github-logo-32px.png\" alt=\"GitHub logo\">\n",
    "      Veja no GitHub\n",
    "    </a>\n",
    "  </td>\n",
    "  <td>\n",
    "    <a href=\"https://console.cloud.google.com/vertex-ai/workbench/deploy-notebook?download_url=https://raw.githubusercontent.com/GoogleCloudPlatform/generative-ai/blob/main/language/intro_palm_api.ipynb\">\n",
    "      <img src=\"https://lh3.googleusercontent.com/UiNooY4LUgW_oTvpsNhPpQzsstV5W8F7rYgxgGBD85cWJoLmrOzhVs_ksK_vgx40SHs7jCqkTkCk=e14-rj-sc0xffffff-h130-w32\" alt=\"Vertex AI logo\">\n",
    "      Execute no Vertex AI Workbench\n",
    "    </a>\n",
    "  </td>\n",
    "</table>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "tvgnzT1CKxrO"
   },
   "source": [
    "## Vis√£o geral\n",
    "A sumariza√ß√£o de textos produz um resumo conciso de um texto. Existem dois tipos principais de resumo de texto: extrativo e abstrativo. A sumariza√ß√£o extrativa envolve selecionar frases cr√≠ticas do texto original e combin√°-las para formar um resumo. A sumariza√ß√£o abstrativa envolve a gera√ß√£o de novas senten√ßas que representam os pontos principais do texto original. Neste notebook, voc√™ passar√° por alguns exemplos de como LLM podem ajudar na gera√ß√£o de sum√°rios de textos.\n",
    "\n",
    "Saiba mais sobre resumo de texto na [documenta√ß√£o oficial](https://cloud.google.com/vertex-ai/docs/generative-ai/text/summarization-prompts)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "d975e698c9a4"
   },
   "source": [
    "### Objetivo\n",
    "\n",
    "Neste tutorial, voc√™ aprender√° como usar LLM para sumarizar informa√ß√µes de texto trabalhando com os seguintes exemplos:\n",
    "- Sum√°rio da transcri√ß√£o\n",
    "- Sumariza√ß√£o de texto em bullets\n",
    "- Sum√°rio de di√°logo com tarefas realizadas\n",
    "- Tokeniza√ß√£o de hashtag\n",
    "- Gera√ß√£o de t√≠tulos e cabe√ßalhos\n",
    "\n",
    "Voc√™ tamb√©m aprender√° como avaliar resumos gerados por modelos comparando-os com resumos criados por humanos usando o `ROUGE` como uma estrutura de avalia√ß√£o."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "f6d865e68adb"
   },
   "source": [
    "### Custos\n",
    "Este tutorial usa os seguintes componentes de Google Cloud:\n",
    "\n",
    "* Vertex AI Studio\n",
    "\n",
    "Saiba mais sobre poss√≠veis custos envolvidos [pre√ßos da Vertex AI](https://cloud.google.com/vertex-ai/pricing),\n",
    "e use a [Calculadora de pre√ßos](https://cloud.google.com/products/calculator/)\n",
    "para gerar uma estimativa de custo com base no uso projetado."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "bs9TZo0GJKCR"
   },
   "source": [
    "## Primeiros Passos"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "2a5AEr0lkLKD"
   },
   "source": [
    "### Instalando os SDK da Vertex AI e da Cloud Translate API"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "148dd6321946",
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "!pip install google-cloud-aiplatform --upgrade --user"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "FLVWFKFwkLKE"
   },
   "source": [
    "**Somente Colab:** Descomente a c√©lula a seguir para reiniciar o kernel ou use o bot√£o para reiniciar o kernel."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "_Hsqwn4hkLKE"
   },
   "outputs": [],
   "source": [
    "# # Reinicia automaticamente o kernel ap√≥s as instala√ß√µes para que seu ambiente possa acessar os novos pacotes\n",
    "# import IPython\n",
    "\n",
    "# app = IPython.Application.instance()\n",
    "# app.kernel.do_shutdown(True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Xe7OuYuGkLKF"
   },
   "source": [
    "### Autenticando seu ambiente de notebook\n",
    "* Se voc√™ estiver usando o **Colab** para executar este notebook, descomente a c√©lula abaixo e continue.\n",
    "* Se voc√™ estiver usando o **Vertex AI Workbench**, confira as instru√ß√µes de configura√ß√£o [aqui](../setup-env/README.md)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "U9Gx2SAZkLKF"
   },
   "outputs": [],
   "source": [
    "# from google.colab import auth\n",
    "# auth.authenticate_user()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "960505627ddf"
   },
   "source": [
    "### Importando as bibliotecas necess√°rias"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Somente Colab:** Descomente a c√©lula a seguir para realizar o processo adequado de inicializa√ß√£o da SDK da Vertex AI.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import vertexai\n",
    "\n",
    "# PROJECT_ID = \"[seu-project-id]\"  # @param {type:\"string\"}\n",
    "# vertexai.init(project=PROJECT_ID, location=\"us-central1\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "PyQmSRbKA8r-"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '3' \n",
    "\n",
    "import warnings\n",
    "warnings.simplefilter(\"ignore\", UserWarning)\n",
    "\n",
    "from vertexai.language_models import TextGenerationModel"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "UP76a2la7O-a"
   },
   "source": [
    "#### Carregando o modelo `text-bison`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "7isig7e07O-a"
   },
   "outputs": [],
   "source": [
    "generation_model = TextGenerationModel.from_pretrained(\"text-bison@001\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Mu1UAhoTKn51"
   },
   "source": [
    "## Sumariza√ß√£o de texto"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "TgZvJeBpJKCS"
   },
   "source": [
    "### Sumarizar uma transcri√ß√£o\n",
    "\n",
    "Neste primeiro exemplo, voc√™ resume um texto sobre computa√ß√£o qu√¢ntica."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "UA2NjngeJKCS"
   },
   "outputs": [],
   "source": [
    "prompt = \"\"\"\n",
    "Forne√ßa um resumo muito curto, n√£o mais do que tr√™s frases, para o seguinte artigo:\n",
    "\n",
    "Nossos computadores qu√¢nticos funcionam manipulando qubits de uma forma orquestrada que chamamos de algoritmos qu√¢nticos.\n",
    "O desafio √© que os qubits s√£o t√£o sens√≠veis que at√© mesmo a luz difusa pode causar erros de c√°lculo ‚Äì e o problema piora √† medida que os computadores qu√¢nticos crescem.\n",
    "Isso tem consequ√™ncias significativas, pois os melhores algoritmos qu√¢nticos que conhecemos para executar aplicativos √∫teis exigem que as taxas de erro de nossos qubits sejam muito menores do que as que temos hoje.\n",
    "Para preencher essa lacuna, precisaremos de corre√ß√£o de erro qu√¢ntica.\n",
    "A corre√ß√£o de erros qu√¢nticos protege as informa√ß√µes codificando-as em v√°rios qubits f√≠sicos para formar um ‚Äúqubit l√≥gico‚Äù e acredita-se que seja a √∫nica maneira de produzir um computador qu√¢ntico de grande escala com taxas de erro baixas o suficiente para c√°lculos √∫teis.\n",
    "Em vez de calcular nos pr√≥prios qubits individuais, calcularemos em qubits l√≥gicos. Ao codificar n√∫meros maiores de qubits f√≠sicos em nosso processador qu√¢ntico em um qubit l√≥gico, esperamos reduzir as taxas de erro para permitir algoritmos qu√¢nticos √∫teis.\n",
    "\n",
    "Resumo:\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "print(\n",
    "    generation_model.predict(prompt, temperature=0.2, max_output_tokens=1024, top_k=40, top_p=0.8).text\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "aade04b2e86a"
   },
   "source": [
    "Em vez de um resumo, podemos pedir um TL;DR (*\"too long; didn't read\"* ou \"muito longo; n√£o li\" em tradu√ß√£o livre). Voc√™ pode comparar as diferen√ßas entre as sa√≠das geradas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "0c0c0f3dfe10"
   },
   "outputs": [],
   "source": [
    "prompt = \"\"\"\n",
    "Forne√ßa um TL;DR para o seguinte artigo:\n",
    "\n",
    "Nossos computadores qu√¢nticos funcionam manipulando qubits de uma forma orquestrada que chamamos de algoritmos qu√¢nticos.\n",
    "O desafio √© que os qubits s√£o t√£o sens√≠veis que at√© mesmo a luz difusa pode causar erros de c√°lculo ‚Äì e o problema piora √† medida que os computadores qu√¢nticos crescem.\n",
    "Isso tem consequ√™ncias significativas, pois os melhores algoritmos qu√¢nticos que conhecemos para executar aplicativos √∫teis exigem que as taxas de erro de nossos qubits sejam muito menores do que as que temos hoje.\n",
    "Para preencher essa lacuna, precisaremos de corre√ß√£o de erro qu√¢ntica.\n",
    "A corre√ß√£o de erros qu√¢nticos protege as informa√ß√µes codificando-as em v√°rios qubits f√≠sicos para formar um ‚Äúqubit l√≥gico‚Äù e acredita-se que seja a √∫nica maneira de produzir um computador qu√¢ntico de grande escala com taxas de erro baixas o suficiente para c√°lculos √∫teis.\n",
    "Em vez de calcular nos pr√≥prios qubits individuais, calcularemos em qubits l√≥gicos. Ao codificar n√∫meros maiores de qubits f√≠sicos em nosso processador qu√¢ntico em um qubit l√≥gico, esperamos reduzir as taxas de erro para permitir algoritmos qu√¢nticos √∫teis.\n",
    "\n",
    "TL;DR:\n",
    "\"\"\"\n",
    "\n",
    "print(\n",
    "    generation_model.predict(prompt, temperature=0.2, max_output_tokens=1024, top_k=40, top_p=0.8).text\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "5PATmHivJKCS"
   },
   "source": [
    "### Sumarizar em bullets\n",
    "No exemplo a seguir, voc√™ usa o mesmo texto sobre computa√ß√£o qu√¢ntica, mas pede ao modelo para sumarizar com bullets. Sinta-se √† vontade para alterar o prompt."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "2orkDF2VJKCT"
   },
   "outputs": [],
   "source": [
    "prompt = \"\"\"\n",
    "Forne√ßa um resumo muito curto em quatro bullets para o seguinte artigo:\n",
    "\n",
    "Nossos computadores qu√¢nticos funcionam manipulando qubits de uma forma orquestrada que chamamos de algoritmos qu√¢nticos.\n",
    "O desafio √© que os qubits s√£o t√£o sens√≠veis que at√© mesmo a luz difusa pode causar erros de c√°lculo ‚Äì e o problema piora √† medida que os computadores qu√¢nticos crescem.\n",
    "Isso tem consequ√™ncias significativas, pois os melhores algoritmos qu√¢nticos que conhecemos para executar aplicativos √∫teis exigem que as taxas de erro de nossos qubits sejam muito menores do que as que temos hoje.\n",
    "Para preencher essa lacuna, precisaremos de corre√ß√£o de erro qu√¢ntica.\n",
    "A corre√ß√£o de erros qu√¢nticos protege as informa√ß√µes codificando-as em v√°rios qubits f√≠sicos para formar um ‚Äúqubit l√≥gico‚Äù e acredita-se que seja a √∫nica maneira de produzir um computador qu√¢ntico de grande escala com taxas de erro baixas o suficiente para c√°lculos √∫teis.\n",
    "Em vez de calcular nos pr√≥prios qubits individuais, calcularemos em qubits l√≥gicos. Ao codificar n√∫meros maiores de qubits f√≠sicos em nosso processador qu√¢ntico em um qubit l√≥gico, esperamos reduzir as taxas de erro para permitir algoritmos qu√¢nticos √∫teis.\n",
    "\n",
    "Bullets:\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "print(\n",
    "    generation_model.predict(prompt, temperature=0.2, max_output_tokens=256, top_k=1, top_p=0.8).text\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "yE7y-clBJKCT"
   },
   "source": [
    "### Sumarizar di√°logos com tarefas realizadas\n",
    "O sum√°rio do di√°logo envolve condensar uma conversa em um formato mais curto para que voc√™ n√£o precise ler toda a discuss√£o, mas possa aproveitar um resumo. Neste exemplo, voc√™ pede ao modelo para resumir uma conversa de exemplo entre um cliente de varejo online e um agente de suporte e incluir tarefas no final."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "SV-BWzRhJKCT"
   },
   "outputs": [],
   "source": [
    "prompt = \"\"\"\n",
    "Gere um resumo da conversa a seguir e, no final, resuma as tarefas para o agente de suporte:\n",
    "\n",
    "Cliente: Ol√°, sou Jos√© e recebi o item errado.\n",
    "\n",
    "Agente de suporte: Ol√°, Jos√©. Como voc√™ gostaria de ver isso resolvido?\n",
    "\n",
    "Cliente: Eu quero devolver o item e obter um reembolso, por favor.\n",
    "\n",
    "Agente de Suporte: Claro. Posso processar o reembolso para voc√™ agora. Posso ter o n√∫mero do seu pedido, por favor?\n",
    "\n",
    "Cliente: √â [N√öMERO DO PEDIDO].\n",
    "\n",
    "Agente de suporte: Obrigado. Processei o reembolso e voc√™ receber√° seu dinheiro de volta em 14 dias.\n",
    "\n",
    "Cliente: Muito obrigado.\n",
    "\n",
    "Agente de suporte: De nada, Jos√©. Tenha um bom dia!\n",
    "\n",
    "Resumo:\n",
    "\"\"\"\n",
    "\n",
    "print(\n",
    "    generation_model.predict(prompt, temperature=0.2, max_output_tokens=256, top_k=40, top_p=0.8).text\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "LlOgWzmNJKCT"
   },
   "source": [
    "### Tokeniza√ß√£o de hashtag\n",
    "A tokeniza√ß√£o de hashtag √© o processo de pegar um peda√ßo de texto e obter os \"tokens\" de hashtag. Voc√™ pode usar isso, por exemplo, se quiser gerar hashtags para suas campanhas de m√≠dia social. Neste exemplo, voc√™ pega [este tweet do Google Cloud](https://twitter.com/googlecloud/status/1649127992348606469) e gera algumas hashtags que pode usar."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "BWa8rNV0JKCT"
   },
   "outputs": [],
   "source": [
    "prompt = \"\"\"\n",
    "Tokenize as hashtags deste tweet:\n",
    "\n",
    "Google Cloud\n",
    "@googlecloud\n",
    "Como os dados podem ajudar nosso planeta em mudan√ßa? üåé\n",
    "\n",
    "Em homenagem ao #EarthDay neste fim de semana, estamos orgulhosos de compartilhar como estamos fazendo parceria com\n",
    "@ClimateEngine para aproveitar o poder dos dados geoespaciais e direcionar para um futuro mais sustent√°vel.\n",
    "\n",
    "Confira como ‚Üí https://goo.gle/3mOUfts\n",
    "\"\"\"\n",
    "\n",
    "print(\n",
    "    generation_model.predict(prompt, temperature=0.8, max_output_tokens=1024, top_k=40, top_p=0.8).text\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "7f-w7mUxJKCT"
   },
   "source": [
    "### Gera√ß√£o de t√≠tulos e cabe√ßalhos\n",
    "Abaixo, voc√™ pede ao modelo para gerar cinco op√ß√µes para poss√≠veis combina√ß√µes de t√≠tulo/cabe√ßalho para um determinado trecho de texto."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "MWNri4DTJKCU"
   },
   "outputs": [],
   "source": [
    "prompt = \"\"\"\n",
    "Escreva um t√≠tulo para este texto, me d√™ cinco op√ß√µes:\n",
    "Seja ajudando m√©dicos a identificar doen√ßas ou encontrando fotos de ‚Äúabra√ßos‚Äù, a IA est√° por tr√°s de muito do trabalho que fazemos no Google. E em nosso Arts & Culture Lab em Paris, temos experimentado como a IA pode ser usada em benef√≠cio da cultura.\n",
    "Hoje, estamos compartilhando nossos √∫ltimos experimentos - prot√≥tipos que se baseiam em sete anos de trabalho em parceria com 1.500 institui√ß√µes culturais em todo o mundo.\n",
    "Cada um desses aplicativos experimentais executa algoritmos de IA em segundo plano para permitir que voc√™ descubra conex√µes culturais escondidas em arquivos e at√© mesmo encontre obras de arte que combinem com a decora√ß√£o da sua casa.\"\n",
    "\"\"\"\n",
    "\n",
    "print(\n",
    "    generation_model.predict(prompt, temperature=0.8, max_output_tokens=256, top_k=1, top_p=0.8).text\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "zcpmZnwKJKCU"
   },
   "source": [
    "## Avalia√ß√£o\n",
    "Voc√™ pode avaliar os resultados das tarefas de resumo usando [ROUGE](https://en.wikipedia.org/wiki/ROUGE_(metric)) como uma estrutura de avalia√ß√£o. `ROUGE` (Recall-Oriented Understudy for Gisting Evaluation) s√£o medidas para determinar automaticamente a qualidade de um resumo comparando-o com outros resumos (ideais) criados por humanos. As medidas contam o n√∫mero de unidades sobrepostas, como n-gram, sequ√™ncias de palavras e pares de palavras entre o resumo gerado por computador a ser avaliado e os resumos ideais criados por humanos.\n",
    "\n",
    "\n",
    "O primeiro passo √© instalar a biblioteca `ROUGE`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "tJcl38ElJKCU"
   },
   "outputs": [],
   "source": [
    "!pip install rouge"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "iD9eKq3SJKCU"
   },
   "source": [
    "Crie um resumo a partir de um LLM que voc√™ pode usar para comparar com um resumo gerado por humanos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "37m_fb-HJKCU"
   },
   "outputs": [],
   "source": [
    "from rouge import Rouge\n",
    "\n",
    "ROUGE = Rouge()\n",
    "\n",
    "prompt = \"\"\"\n",
    "Forne√ßa um resumo muito curto, m√°ximo de quatro frases, para o seguinte artigo:\n",
    "\n",
    "Nossos computadores qu√¢nticos funcionam manipulando qubits de uma forma orquestrada que chamamos de algoritmos qu√¢nticos.\n",
    "O desafio √© que os qubits s√£o t√£o sens√≠veis que at√© mesmo a luz difusa pode causar erros de c√°lculo ‚Äì e o problema piora √† medida que os computadores qu√¢nticos crescem.\n",
    "Isso tem consequ√™ncias significativas, pois os melhores algoritmos qu√¢nticos que conhecemos para executar aplicativos √∫teis exigem que as taxas de erro de nossos qubits sejam muito menores do que as que temos hoje.\n",
    "Para preencher essa lacuna, precisaremos de corre√ß√£o de erro qu√¢ntica.\n",
    "A corre√ß√£o de erros qu√¢nticos protege as informa√ß√µes codificando-as em v√°rios qubits f√≠sicos para formar um ‚Äúqubit l√≥gico‚Äù e acredita-se que seja a √∫nica maneira de produzir um computador qu√¢ntico de grande escala com taxas de erro baixas o suficiente para c√°lculos √∫teis.\n",
    "Em vez de calcular nos pr√≥prios qubits individuais, calcularemos em qubits l√≥gicos. Ao codificar n√∫meros maiores de qubits f√≠sicos em nosso processador qu√¢ntico em um qubit l√≥gico, esperamos reduzir as taxas de erro para permitir algoritmos qu√¢nticos √∫teis.\n",
    "\n",
    "Resumo:\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "candidate = generation_model.predict(prompt, temperature=0.1, max_output_tokens=1024, top_k=40, top_p=0.9).text\n",
    "\n",
    "print(candidate)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "b44f9872e1ba"
   },
   "source": [
    "You will also need a human-generated summary that we will use to compare to the `candidate` generated by the model. We will call this `reference`. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "D0qNdPzOJKCc"
   },
   "outputs": [],
   "source": [
    "reference = \"Computadores qu√¢nticos s√£o sens√≠veis a ru√≠dos e erros. Para preencher essa lacuna, precisaremos de corre√ß√£o de erros qu√¢nticos. A corre√ß√£o de erros qu√¢nticos protege as informa√ß√µes codificando v√°rios qubits f√≠sicos para formar um 'qubit l√≥gico'.\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "1KKaYhzwJKCc"
   },
   "source": [
    "Agora voc√™ pode pegar o candidato e a refer√™ncia para avaliar o desempenho. Neste caso, ROUGE lhe dar√°:\n",
    "\n",
    "- `rouge-1`, que mede a sobreposi√ß√£o de unigramas\n",
    "- `rouge-2`, que mede a sobreposi√ß√£o de bigramas\n",
    "- `rouge-l`, que mede a maior subsequ√™ncia comum"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "FHUH6VuTJKCc"
   },
   "outputs": [],
   "source": [
    "ROUGE.get_scores(candidate, reference)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "name": "text_summarization.ipynb",
   "toc_visible": true
  },
  "environment": {
   "kernel": "python3",
   "name": "tf2-gpu.2-11.m109",
   "type": "gcloud",
   "uri": "gcr.io/deeplearning-platform-release/tf2-gpu.2-11:m109"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
