{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ur8xi4C7S06n"
   },
   "outputs": [],
   "source": [
    "# Copyright 2023 Google LLC\n",
    "#\n",
    "# Licensed under the Apache License, Version 2.0 (the \"License\");\n",
    "# you may not use this file except in compliance with the License.\n",
    "# You may obtain a copy of the License at\n",
    "#\n",
    "#     https://www.apache.org/licenses/LICENSE-2.0\n",
    "#\n",
    "# Unless required by applicable law or agreed to in writing, software\n",
    "# distributed under the License is distributed on an \"AS IS\" BASIS,\n",
    "# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
    "# See the License for the specific language governing permissions and\n",
    "# limitations under the License."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "JAPoU8Sm5E6e"
   },
   "source": [
    "# Classificação de textos com Generative AI na Vertex AI\n",
    "\n",
    "<table align=\"left\">\n",
    "  <td>\n",
    "    <a href=\"https://colab.research.google.com/github/GoogleCloudPlatform/generative-ai/blob/main/language/intro_palm_api.ipynb\">\n",
    "      <img src=\"https://cloud.google.com/ml-engine/images/colab-logo-32px.png\" alt=\"Colab logo\"> Execute no Colab\n",
    "    </a>\n",
    "  </td>\n",
    "  <td>\n",
    "    <a href=\"https://github.com/GoogleCloudPlatform/generative-ai/blob/main/language/intro_palm_api.ipynb\">\n",
    "      <img src=\"https://cloud.google.com/ml-engine/images/github-logo-32px.png\" alt=\"GitHub logo\">\n",
    "      Veja no GitHub\n",
    "    </a>\n",
    "  </td>\n",
    "  <td>\n",
    "    <a href=\"https://console.cloud.google.com/vertex-ai/workbench/deploy-notebook?download_url=https://raw.githubusercontent.com/GoogleCloudPlatform/generative-ai/blob/main/language/intro_palm_api.ipynb\">\n",
    "      <img src=\"https://lh3.googleusercontent.com/UiNooY4LUgW_oTvpsNhPpQzsstV5W8F7rYgxgGBD85cWJoLmrOzhVs_ksK_vgx40SHs7jCqkTkCk=e14-rj-sc0xffffff-h130-w32\" alt=\"Vertex AI logo\">\n",
    "      Execute no Vertex AI Workbench\n",
    "    </a>\n",
    "  </td>\n",
    "</table>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "tvgnzT1CKxrO"
   },
   "source": [
    "## Visão geral\n",
    "\n",
    "Modelos generativos como o PaLM 2 são modelos de linguagem poderosos usados para várias tarefas de processamento de linguagem natural (NLP). Uma delas é a classificação de texto, que envolve a atribuição de uma ou mais categorias a um determinado trecho de texto. Embora a classificação de texto possa ser feita usando técnicas NLP tradicionais, os LLMs podem realizar a classificação fornecendo prompts (em oposição a dados rotulados específicos do domínio), o que pode acelerar o tempo necessário para criar uma solução de classificação de texto. Os modelos de classificação baseados em LLMs podem ser ajustados com muitos exemplos por meio de treinamento de modelo personalizado, mas isso está além do escopo deste notebook.\n",
    "\n",
    "Neste notebook, você explorará como fazer classificação de texto usando prompts com a API PaLM. Saiba mais sobre os prompts de classificação na [documentação oficial](https://cloud.google.com/vertex-ai/docs/generative-ai/text/classification-prompts)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "d975e698c9a4"
   },
   "source": [
    "### Objetivo\n",
    "\n",
    "No final do notebook, você será capaz de usar um LLM para executar várias tarefas de classificação, incluindo:\n",
    "\n",
    "* Classificação de texto com prompt zero-shot\n",
    "* Classificação de texto com prompt few-shot\n",
    "* Tarefas como:\n",
    "     * Análise de sentimentos\n",
    "     * Classificação do tópico\n",
    "     * Detecção de spam\n",
    "     * Reconhecimento de intenção\n",
    "     * Identificação do idioma\n",
    "     * Detecção de toxicidade\n",
    "     * Detecção de emoções"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Custos\n",
    "Este tutorial usa os seguintes componentes de Google Cloud:\n",
    "\n",
    "* Vertex AI Studio\n",
    "\n",
    "Saiba mais sobre possíveis custos envolvidos [preços da Vertex AI](https://cloud.google.com/vertex-ai/pricing),\n",
    "e use a [Calculadora de preços](https://cloud.google.com/products/calculator/)\n",
    "para gerar uma estimativa de custo com base no uso projetado."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "nSyXtwyz_o_v"
   },
   "source": [
    "## Primeiros Passos"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "2a5AEr0lkLKD"
   },
   "source": [
    "### Instalando os SDK da Vertex AI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "82ad0c445061",
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "!pip install google-cloud-aiplatform --upgrade --user"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Somente Colab:** Descomente a célula a seguir para reiniciar o kernel ou use o botão para reiniciar o kernel."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "_Hsqwn4hkLKE"
   },
   "outputs": [],
   "source": [
    "# # Reinicia automaticamente o kernel após as instalações para que seu ambiente possa acessar os novos pacotes\n",
    "# import IPython\n",
    "\n",
    "# app = IPython.Application.instance()\n",
    "# app.kernel.do_shutdown(True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Xe7OuYuGkLKF"
   },
   "source": [
    "### Autenticando seu ambiente de notebook\n",
    "* Se você estiver usando o **Colab** para executar este notebook, descomente a célula abaixo e continue.\n",
    "* Se você estiver usando o **Vertex AI Workbench**, confira as instruções de configuração [aqui](../../setup-env/README.md)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "U9Gx2SAZkLKF"
   },
   "outputs": [],
   "source": [
    "# from google.colab import auth\n",
    "# auth.authenticate_user()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "960505627ddf"
   },
   "source": [
    "### Importando as bibliotecas necessárias"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Somente Colab:** Descomente a célula a seguir para realizar o processo adequado de inicialização da SDK da Vertex AI.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import vertexai\n",
    "\n",
    "# PROJECT_ID = \"[seu-project-id]\"  # @param {type:\"string\"}\n",
    "# vertexai.init(project=PROJECT_ID, location=\"us-central1\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "PyQmSRbKA8r-"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '3' \n",
    "\n",
    "import warnings\n",
    "warnings.simplefilter(\"ignore\", UserWarning)\n",
    "\n",
    "\n",
    "import pandas as pd\n",
    "from vertexai.language_models import TextGenerationModel"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "UP76a2la7O-a"
   },
   "source": [
    "#### Carregando o modelo `text-bison`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "7isig7e07O-a"
   },
   "outputs": [],
   "source": [
    "generation_model = TextGenerationModel.from_pretrained(\"text-bison@001\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "fIPcn5dZ7O-b"
   },
   "source": [
    "## Classificação de texto"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "l2eDjxvafo5W"
   },
   "source": [
    "Na seção abaixo, você explorará prompts zero-shot, few-shot e alguns tipos comuns de tarefas de classificação de texto."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "bC3qkPZ8jFkY"
   },
   "source": [
    "### Prompt zero-shot"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "W8RFu2ZX_o_y"
   },
   "source": [
    "O prompt zero-shot é onde você não fornece exemplos com rótulos e conta com o LLM para fazer a classificação por conta própria."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "_uNNGhC_e1nZ"
   },
   "outputs": [],
   "source": [
    "prompt = \"\"\"\n",
    "Classifique a texto abaixo:\\n\n",
    "texto: \"Hoje eu vi um animal peludo no parque - Ele tinha um rabo logo e grandes olhos.\"\n",
    "classe: cachorros, gatos\n",
    "\"\"\"\n",
    "\n",
    "print(\n",
    "    generation_model.predict(prompt=prompt, max_output_tokens=256, temperature=0.1).text\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "tjl-tckTjK2B"
   },
   "source": [
    "### Prompt few-shot"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "5UC0w7n5_o_z"
   },
   "source": [
    "Com prompt few-shot, você fornece exemplos para o modelo PaLM e espera que ele faça a classificação com base nos exemplos fornecidos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "b8jYL-hBjMtW"
   },
   "outputs": [],
   "source": [
    "prompt = \"\"\"\n",
    "Qual é o assunto de uma determinada manchete de notícias? \\n\n",
    "- negócios \\n\n",
    "- entretenimento \\n\n",
    "- saúde \\n\n",
    "- esportes \\n\n",
    "- tecnologia \\n\\n\n",
    "\n",
    "Texto: revisão prática do especialista do Pixel 7 Pro. \\n\n",
    "A resposta é: tecnologia \\n\n",
    "\n",
    "Texto: Parar de fumar? \\n\n",
    "A resposta é: saúde \\n\n",
    "\n",
    "Texto: Passarinhos ou bichos-papões? As 5 principais dicas para bater abaixo do par \\n\n",
    "A resposta é: esportes \\n\n",
    "\n",
    "Texto: Alívio do aumento do salário mínimo local parece mais remoto \\n\n",
    "A resposta é: negócios \\n\n",
    "\n",
    "Texto: Você não vai adivinhar quem acabou de chegar a Bari, na Itália, para a estreia do filme. \\n\n",
    "A resposta é:\n",
    "\"\"\"\n",
    "\n",
    "print(\n",
    "    generation_model.predict(prompt=prompt, max_output_tokens=256, temperature=0.1).text\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "WaiMLs4SjNLi"
   },
   "source": [
    "### Outros exemplos de classificação"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "LhkcRWrh_o_0"
   },
   "source": [
    "Explore alguns prompts de classificação de texto mais comuns abaixo, todos baseados em prompts zero-shot. Você também pode transformar alguns deles em prompts few-shot, fornecendo seus próprios exemplos personalizados de texto e as classes de saída associadas."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "8tEjKEAtXjf8"
   },
   "source": [
    "#### Classificação de tópico"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "bCnuQRVSXmyr"
   },
   "outputs": [],
   "source": [
    "prompt = \"\"\"\n",
    "Classifique um trecho de texto em um dos vários tópicos predefinidos, como esportes, política ou entretenimento. \\n\n",
    "texto: O presidente Biden visitará a Índia no mês de março para discutir algumas oportunidades. \\n\n",
    "classe:\n",
    "\"\"\"\n",
    "\n",
    "print(\n",
    "    generation_model.predict(prompt=prompt, max_output_tokens=256, temperature=0.1).text\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "rB6rZD-6YAkC"
   },
   "source": [
    "####  Detecção de spam"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "OfyHvhBfX_P_"
   },
   "outputs": [],
   "source": [
    "prompt = \"\"\"\n",
    "Dado um e-mail, classifique-o como spam ou não spam. \\n\n",
    "e-mail: oi usuário, \\n\n",
    "       você foi selecionado como vencedor da loteria e pode ganhar até 1 milhão de dólares. \\n\n",
    "       gentilmente compartilhe seus dados bancários e podemos prosseguir a partir daí. \\n\\n\n",
    "\n",
    "       de, \\n\n",
    "       Departamento oficial de loteria dos EUA\n",
    "\"\"\"\n",
    "\n",
    "print(\n",
    "    generation_model.predict(prompt=prompt, max_output_tokens=256, temperature=0.1).text\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "cHKcxx0TYrGv"
   },
   "source": [
    "#### Reconhecimento de intenção"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "DsseGvWNYvK3"
   },
   "outputs": [],
   "source": [
    "prompt = \"\"\"\n",
    "Dada a entrada de um usuário, classifique sua intenção, como \"encontrar informações\", \"fazer uma reserva\" ou \"fazer um pedido\". \\n\n",
    "entrada do usuário: Olá, você pode agendar uma mesa para dois no Restaurante Google para 1º de maio?\n",
    "\"\"\"\n",
    "\n",
    "print(\n",
    "    generation_model.predict(prompt=prompt, max_output_tokens=256, temperature=0.1).text\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "stsfav5aZtqV"
   },
   "source": [
    "#### Identificação de linguagem"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "88TqQSXIZxts"
   },
   "outputs": [],
   "source": [
    "prompt = \"\"\"\n",
    "Dado um pedaço de texto, classifique o idioma em que está escrito. \\n\n",
    "texto: Selam nasıl gidiyor?\n",
    "linguagem:\n",
    "\"\"\"\n",
    "\n",
    "print(\n",
    "    generation_model.predict(prompt=prompt, max_output_tokens=256, temperature=0.1).text\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "3Z_jmrhOZ15J"
   },
   "source": [
    "#### Detecção de toxicidade"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Umloy-o1Z5us"
   },
   "outputs": [],
   "source": [
    "prompt = \"\"\"\n",
    "Dado um trecho de texto, classifique-o como tóxico ou não tóxico. \\n\n",
    "texto: Tente que você consegue.\n",
    "\"\"\"\n",
    "\n",
    "print(\n",
    "    generation_model.predict(prompt=prompt, max_output_tokens=256, temperature=0.1).text\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "rTH5MeiVZ6Hr"
   },
   "source": [
    "#### Detecção de emoção"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "u5ETwBSrZ-Xn"
   },
   "outputs": [],
   "source": [
    "prompt = \"\"\"\n",
    "Dado um trecho de texto, classifique a emoção que ele transmite, como 'felicidade' ou 'raiva'. \\n\n",
    "texto: Estou muito feliz com as notícias de ontem\n",
    "\"\"\"\n",
    "\n",
    "print(\n",
    "    generation_model.predict(prompt=prompt, max_output_tokens=256, temperature=0.5).text\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "7ddaadac64c7"
   },
   "source": [
    "### Avaliação"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "d5e2266cb257"
   },
   "source": [
    "Você pode avaliar as saídas da tarefa de classificação de texto se as classes de informações básicas estiverem disponíveis. Para mostrar como isso funciona, comece criando um dataframe simples com análises de produtos e o sentimento de verdade."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "b0e04a03f24f"
   },
   "outputs": [],
   "source": [
    "review_data = {\n",
    "    \"review\": [\n",
    "        \"adoro este produto. Tem tudo o que procuro!\",\n",
    "        \"tudo o que posso dizer é que você ficará feliz depois de comprar este produto\",\n",
    "        \"é muito caro e não vale o preço\",\n",
    "        \"Ele é ok. Não é bom nem muito ruim.\",\n",
    "    ],\n",
    "    \"sentiment_groundtruth\": [\"positivo\", \"positivo\", \"negativo\", \"neutro\"],\n",
    "}\n",
    "\n",
    "review_data_df = pd.DataFrame(review_data)\n",
    "review_data_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "088327f41a26"
   },
   "source": [
    "Agora que você tem os dados com avaliações e sentimentos como rótulos de informações básicas, pode chamar o modelo de geração de texto para cada linha de avaliação usando a função `apply`. Cada linha usará o prompt na coluna `review` para prever o sentimento usando a API PaLM e armazenará os resultados na coluna `sentiment_prediction`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "0fb691b6c721"
   },
   "outputs": [],
   "source": [
    "def get_sentiment(row):\n",
    "    prompt = f\"\"\"Classifique o sentimento dos reviews abaixo como \"positivo\", \"neutro\" ou \"negativo\". \\n\\n\n",
    "                review: {row} \\n\n",
    "                sentimento:\n",
    "              \"\"\"\n",
    "    response = generation_model.predict(prompt=prompt).text\n",
    "    return response\n",
    "\n",
    "\n",
    "review_data_df[\"sentiment_prediction\"] = review_data_df[\"review\"].apply(get_sentiment)\n",
    "review_data_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "908c72bdf4c7"
   },
   "source": [
    "No final, você pode chamar a função `classification_report` do móulo `scikit-learn` para medir a precisão e outras métricas de classificação, passando sentimentos de verdade absoluta `sentiment_groundtruth` e sentimento previsto `sentiment_prediction`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "7f22690ae395"
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "\n",
    "print(\n",
    "    classification_report(\n",
    "        review_data_df[\"sentiment_groundtruth\"], review_data_df[\"sentiment_prediction\"]\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "name": "text_classification.ipynb",
   "toc_visible": true
  },
  "environment": {
   "kernel": "python3",
   "name": "tf2-gpu.2-11.m109",
   "type": "gcloud",
   "uri": "gcr.io/deeplearning-platform-release/tf2-gpu.2-11:m109"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
