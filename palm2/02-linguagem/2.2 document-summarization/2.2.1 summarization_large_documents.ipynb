{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "uxCkB_DXTHzf"
   },
   "outputs": [],
   "source": [
    "# Copyright 2023 Google LLC\n",
    "#\n",
    "# Licensed under the Apache License, Version 2.0 (the \"License\");\n",
    "# you may not use this file except in compliance with the License.\n",
    "# You may obtain a copy of the License at\n",
    "#\n",
    "#     https://www.apache.org/licenses/LICENSE-2.0\n",
    "#\n",
    "# Unless required by applicable law or agreed to in writing, software\n",
    "# distributed under the License is distributed on an \"AS IS\" BASIS,\n",
    "# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
    "# See the License for the specific language governing permissions and\n",
    "# limitations under the License."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Hny4I-ODTIS6"
   },
   "source": [
    "# Sumarização de textos em documentos grandes\n",
    "\n",
    "\n",
    "<table align=\"left\">\n",
    "\n",
    "  <td>\n",
    "    <a href=\"https://colab.research.google.com/github/GoogleCloudPlatform/generative-ai/blob/main/language/examples/reference-architectures/text_summarization_for_large_documents.ipynb\">\n",
    "      <img src=\"https://cloud.google.com/ml-engine/images/colab-logo-32px.png\" alt=\"Colab logo\"> Run in Colab\n",
    "    </a>\n",
    "  </td>\n",
    "  <td>\n",
    "    <a href=\"https://github.com/GoogleCloudPlatform/generative-ai/blob/main/language/examples/reference-architectures/text_summarization_for_large_documents.ipynb\">\n",
    "      <img src=\"https://cloud.google.com/ml-engine/images/github-logo-32px.png\" alt=\"GitHub logo\">\n",
    "      View on GitHub\n",
    "    </a>\n",
    "  </td>\n",
    "  <td>\n",
    "    <a href=\"https://console.cloud.google.com/vertex-ai/workbench/deploy-notebook?download_url=https://raw.githubusercontent.com/GoogleCloudPlatform/generative-ai/blob/main/language/examples/reference-architectures/text_summarization_for_large_documents.ipynb\">\n",
    "      <img src=\"https://lh3.googleusercontent.com/UiNooY4LUgW_oTvpsNhPpQzsstV5W8F7rYgxgGBD85cWJoLmrOzhVs_ksK_vgx40SHs7jCqkTkCk=e14-rj-sc0xffffff-h130-w32\" alt=\"Vertex AI logo\">\n",
    "      Open in Vertex AI Workbench\n",
    "    </a>\n",
    "  </td>\n",
    "</table>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-nLS57E2TO5y"
   },
   "source": [
    "## Visão geral\n",
    "\n",
    "O resumo de texto é o processo de criar uma versão mais curta de um documento de texto, preservando as informações mais importantes. Isso pode ser útil para várias finalidades, como examinar rapidamente um documento longo, obter a essência de um artigo ou compartilhar um resumo com outras pessoas.\n",
    "\n",
    "Embora resumir um parágrafo curto seja uma tarefa trivial, há alguns desafios a serem superados se você quiser resumir um documento grande, como um arquivo PDF com várias páginas. Neste notebook, você passará por alguns exemplos de como usar modelos generativos para resumir documentos grandes."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "iXsvgIuwTPZw"
   },
   "source": [
    "### Objetivo\n",
    "\n",
    "Neste tutorial, você aprenderá como usar modelos generativos para resumir informações de texto trabalhando com os seguintes exemplos:\n",
    "\n",
    "- Método de *stuffing*\n",
    "- Método MapReduce\n",
    "- MapReduce com Overlapping Chunks\n",
    "- MapReduce com Rolling Summary"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "skXAu__iqks_"
   },
   "source": [
    "### Custos\n",
    "Este tutorial usa os seguintes componentes de Google Cloud:\n",
    "\n",
    "* Vertex AI Studio\n",
    "\n",
    "Saiba mais sobre possíveis custos envolvidos [preços da Vertex AI](https://cloud.google.com/vertex-ai/pricing),\n",
    "e use a [Calculadora de preços](https://cloud.google.com/products/calculator/)\n",
    "para gerar uma estimativa de custo com base no uso projetado."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "mvKl-BtQTRiQ"
   },
   "source": [
    "## Primeiros Passos"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "PwFMpIMrTV_4"
   },
   "source": [
    "### Instalando o SDK da Vertex AI e outras dependências"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "WYUu8VMdJs3V",
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "!pip install --user google-cloud-aiplatform PyPDF2 ratelimit backoff==1.10.0 --upgrade"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "jWwtjLV5TY6H"
   },
   "source": [
    "**Somente Colab:** Descomente a célula a seguir para reiniciar o kernel ou use o botão para reiniciar o kernel."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "XRvKdaPDTznN"
   },
   "outputs": [],
   "source": [
    "# # Reinicia automaticamente o kernel após as instalações para que seu ambiente possa acessar os novos pacotes\n",
    "# import IPython\n",
    "\n",
    "# app = IPython.Application.instance()\n",
    "# app.kernel.do_shutdown(True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "opUxT_k5TdgP"
   },
   "source": [
    "### Autenticando seu ambiente de notebook\n",
    "* Se você estiver usando o **Colab** para executar este notebook, descomente a célula abaixo e continue.\n",
    "* Se você estiver usando o **Vertex AI Workbench**, confira as instruções de configuração [aqui](../setup-env/README.md)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "vbNgv4q1T2Mi"
   },
   "outputs": [],
   "source": [
    "# from google.colab import auth\n",
    "# auth.authenticate_user()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "n5fXfvzhTkYN"
   },
   "source": [
    "### Importando as bibliotecas necessárias"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "uCGlGzd1ihnf"
   },
   "source": [
    "**Somente Colab:** Descomente a célula a seguir para realizar o processo adequado de inicialização da SDK da Vertex AI.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "GjSsu6cmUdEx"
   },
   "outputs": [],
   "source": [
    "# import vertexai\n",
    "\n",
    "# PROJECT_ID = \"[your-project-id]\"  # @param {type:\"string\"}\n",
    "# vertexai.init(project=PROJECT_ID, location=\"us-central1\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "cRkcfnQMT9vD"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '3' \n",
    "\n",
    "import warnings\n",
    "warnings.simplefilter(\"ignore\", UserWarning)\n",
    "\n",
    "import re\n",
    "import urllib\n",
    "import warnings\n",
    "from pathlib import Path\n",
    "\n",
    "import backoff\n",
    "import pandas as pd\n",
    "import PyPDF2\n",
    "import ratelimit\n",
    "from google.api_core import exceptions\n",
    "from tqdm import tqdm\n",
    "from vertexai.language_models import TextGenerationModel\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "DAGaTjPVTmhP"
   },
   "source": [
    "#### Carregando o modelo `text-bison`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ITUmZiNZcMUW"
   },
   "outputs": [],
   "source": [
    "generation_model = TextGenerationModel.from_pretrained(\"text-bison@001\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "HZkLDRTjTcfm"
   },
   "source": [
    "### Preparando arquivos de dados\n",
    "\n",
    "Para começar, você precisará baixar um arquivo pdf para as tarefas de resumo abaixo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "hLtMd97SoTBE",
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "!pwd\n",
    "# le o arquivo pdf e cria uma lista de páginas\n",
    "pdf_file = './documentos/documento.pdf'\n",
    "reader = PyPDF2.PdfReader(pdf_file)\n",
    "pages = reader.pages\n",
    "\n",
    "# lista o conteúdo de 3 páginas do pdf\n",
    "for i in range(3):\n",
    "    text = pages[i].extract_text().strip()\n",
    "    print(f\"Page {i}: {text} \\n\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ZDVwBFSjZ7ws"
   },
   "source": [
    "## Método 1: Stuffing\n",
    "\n",
    "A maneira mais simples de passar dados para um modelo de linguagem é enviá-los no prompt como contexto. Isso significa simplesmente incluir todas as informações relevantes no prompt, na ordem em que você deseja que o modelo as processe.\n",
    "\n",
    "Aqui você extrairá o texto de todas as páginas do arquivo pdf."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "eH3Y3X8hJs3X"
   },
   "outputs": [],
   "source": [
    "# le o pdf e cria a lista de páginas\n",
    "reader = PyPDF2.PdfReader(pdf_file)\n",
    "pages = reader.pages\n",
    "\n",
    "# variável que oncatena todos os textos extraídos\n",
    "concatenated_text = \"\"\n",
    "\n",
    "# loop nas páginas\n",
    "for page in tqdm(pages):\n",
    "\n",
    "    # extrai o texto das páginas e remove espaços em branco\n",
    "    text = page.extract_text().strip()\n",
    "\n",
    "    # concatena o texto extraído\n",
    "    concatenated_text += text\n",
    "\n",
    "print(f\"Há {len(concatenated_text)} cadeias de texto no pdf\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "fOMGiUAaiy3Y"
   },
   "source": [
    "Agora você criará um modelo de prompt que pode ser usado posteriormente no notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "eDBlvprWizgW"
   },
   "outputs": [],
   "source": [
    "prompt_template = \"\"\"\n",
    "    Escreva um sumário conciso do texto abaixo delimitado por três aspas invertidas.\n",
    "    Retorne sua resposta em bullets que cubram os pontos principais do texto.\n",
    "\n",
    "    ```{text}```\n",
    "\n",
    "    SUMARIO EM BULLETS:\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "x_xMwRLuyDrj"
   },
   "source": [
    "Aqui você usará o LLM via API para resumir os textos extraídos. Observe que os LLMs atualmente têm limite de texto de entrada e o preenchimento de um texto de entrada grande pode não ser aceito. Você pode ler mais sobre cotas e limites [aqui](https://cloud.google.com/vertex-ai/docs/quotas).\n",
    "\n",
    "O código a seguir causará **uma exceção (um erro)**!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "RtgemmBzkddX",
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "# define o prompt usando a template criada anteriormente\n",
    "prompt = prompt_template.format(text=concatenated_text)\n",
    "\n",
    "# usa o modelo para sumarizar o texto\n",
    "summary = generation_model.predict(prompt=prompt, max_output_tokens=1024).text\n",
    "\n",
    "print(summary)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "N5aVrDWkJs3Y"
   },
   "source": [
    "#### Tentando novamente\n",
    "\n",
    "O modelo respondeu com uma mensagem de erro: **400 Request contains an invalid argument** porque o texto extraído é muito longo para o modelo generativo processar.\n",
    "\n",
    "Para evitar esse problema, você inserirá apenas uma parte do texto extraído (por exemplo, as primeiras 30.000 palavras)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "MmUwTIjMk58J"
   },
   "outputs": [],
   "source": [
    "# Define the prompt using the prompt template\n",
    "prompt = prompt_template.format(text=concatenated_text[:30000])\n",
    "\n",
    "# Use the model to summarize the text using the prompt\n",
    "summary = generation_model.predict(prompt=prompt, max_output_tokens=1024).text\n",
    "\n",
    "print(summary)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Vtp21WX3T7d_"
   },
   "source": [
    "### Recapitulando\n",
    "\n",
    "Embora o texto completo seja muito grande para o modelo, você conseguiu criar uma lista concisa e com marcadores das informações mais importantes de uma parte do PDF usando o modelo. Assim, aqui estão os prós e contras de usar o método de stuffing:\n",
    "\n",
    "**Prós:**\n",
    "- Exigiu apenas uma única chamada para o modelo.\n",
    "- Ao resumir o texto, o modelo tem acesso a todos os dados de uma só vez para que o resultado seja melhor.\n",
    "\n",
    "**Contras:**\n",
    "- A maioria dos modelos tem um comprimento de contexto e, para documentos grandes (ou muitos documentos), isso não funcionará, pois resultará em um prompt maior que o comprimento do contexto.\n",
    "- Este método funciona apenas em pedaços menores de dados e não é adequado para documentos grandes na maioria das vezes.\n",
    "\n",
    "Na sessão seguinte, você explorará abordagens projetadas para ajudar a lidar com textos mais longos do que o limite de comprimento de contexto dos LLMs."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "wOY5LHl9Js3Y"
   },
   "source": [
    "### Adicionando limite para chamadas de modelo\n",
    "\n",
    "Ao usar MapReduce ou outros métodos semelhantes, você fará várias chamadas de API para o modelo em um curto período de tempo. Há um limite para o número de chamadas de API que você pode fazer por minuto, portanto, você precisará adicionar uma medida de segurança ao seu código para evitar que o limite seja excedido. Isso ajudará a garantir que seu código seja executado sem problemas e não encontre nenhum erro.\n",
    "\n",
    "Para este método, aqui estão algumas coisas específicas que você fará:\n",
    "1. Você usará uma biblioteca Python chamada [ratelimit](https://pypi.org/project/ratelimit/) para limitar o número de chamadas de API por minuto\n",
    "2. Você usará uma biblioteca Python chamada [backoff](https://pypi.org/project/backoff/) para tentar novamente até que o limite máximo de tempo seja atingido\n",
    "\n",
    "A função a seguir melhora o processo de chamada de API limitando o número de chamadas a **20 por minuto**. Ele também recua e tenta novamente chamar a API depois de encontrar a exceção **Resource Exhausted**. A duração da espera aumenta **exponencialmente até a marca de 5 minutos**, e então a função desistirá ao tentar novamente."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "0uziSPeEJs3Y"
   },
   "outputs": [],
   "source": [
    "CALL_LIMIT = 20  # número de chamadas permitido por intervalo de tempo\n",
    "ONE_MINUTE = 60  # um minuto em segundos\n",
    "FIVE_MINUTE = 5 * ONE_MINUTE\n",
    "\n",
    "# uma função que mostra a mensagem quando acontecer uma nova tentativa\n",
    "def backoff_hdlr(details):\n",
    "    print(\n",
    "        \"Backing off {} seconds after {} tries\".format(\n",
    "            details[\"wait\"], details[\"tries\"]\n",
    "        )\n",
    "    )\n",
    "\n",
    "\n",
    "@backoff.on_exception(  # novas tentativas com a estratégia de backoff\n",
    "    backoff.expo,\n",
    "    (\n",
    "        exceptions.ResourceExhausted,\n",
    "        ratelimit.RateLimitException,\n",
    "    ),  # exceções para novas tentativas\n",
    "    max_time=FIVE_MINUTE,\n",
    "    on_backoff=backoff_hdlr,  # função a ser chamada quando tentando novamente\n",
    ")\n",
    "@ratelimit.limits(  # limite do número de chamadas ao modelo por minuto\n",
    "    calls=CALL_LIMIT, period=ONE_MINUTE\n",
    ")\n",
    "\n",
    "# esta função chamará a função `generation_model.predict`, mas tentará novamente se ocorrerem exceções definidas.\n",
    "def model_with_limit_and_backoff(**kwargs):\n",
    "    return generation_model.predict(**kwargs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "RM3V1JARZ9-k"
   },
   "source": [
    "## Método 2: MapReduce\n",
    "\n",
    "Esse método funciona primeiro dividindo os dados grandes em blocos e, em seguida, executando um prompt em cada bloco de texto. Para tarefas de resumo, a saída do prompt inicial seria um resumo desse bloco. Uma vez que todas as saídas iniciais tenham sido geradas, um prompt diferente é executado para combiná-los.\n",
    "\n",
    "Esse método é um pouco mais complexo que o primeiro método, mas pode ser mais eficaz para grandes conjuntos de dados. Aqui você preparará dois modelos de prompt: um para a etapa inicial de resumo e outro para a etapa final de combinação. Você usará esses dois modelos posteriormente neste notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "fs4rmcL-Js3Y"
   },
   "outputs": [],
   "source": [
    "initial_prompt_template = \"\"\"\n",
    "    Escreva um sumário conciso sobre o texto abaixo delimitado por três aspas invertidas.\n",
    "\n",
    "    ```{text}```\n",
    "\n",
    "    SUMARIO CONCISO:\n",
    "\"\"\"\n",
    "\n",
    "final_prompt_template = \"\"\"\n",
    "    Escreva um cenário conciso do texto abaixo delimitdo por aspas invertidas.\n",
    "    Retorne sua resposta em bullets que cubram os pontos principais do texto.\n",
    "\n",
    "    ```{text}```\n",
    "\n",
    "    SUMARIO EM BULLETS:\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "eo5NkotOJs3Y"
   },
   "source": [
    "#### Etapa de Map\n",
    "\n",
    "Nesta seção, você lerá o arquivo PDF novamente e usará o modelo para resumir cada página individualmente usando o modelo de prompt inicial."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "aRub85PIJs3Y"
   },
   "outputs": [],
   "source": [
    "# le o arquivo pdf e cria uma lista de páginas\n",
    "reader = PyPDF2.PdfReader(pdf_file)\n",
    "pages = reader.pages\n",
    "\n",
    "# cria uma lista para armazenar os sumários\n",
    "initial_summary = []\n",
    "\n",
    "# iteração nas páginas e eração do sumário de cada página\n",
    "for page in tqdm(pages):\n",
    "\n",
    "    # extrai o texto da página e remove os espaços\n",
    "    text = page.extract_text().strip()\n",
    "\n",
    "    # cria o prompt usando o texto extraído e a template de prompt\n",
    "    prompt = initial_prompt_template.format(text=text)\n",
    "\n",
    "    # gera o sumário usando o modelo e o prompt\n",
    "    summary = model_with_limit_and_backoff(prompt=prompt, max_output_tokens=1024).text\n",
    "\n",
    "    # faz o append do sumário da página na lista de sumários\n",
    "    initial_summary.append(summary)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "pLLAUkuNDLbp"
   },
   "source": [
    "Dê uma olhada nos primeiros resumos da frase inicial de Map."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "i3CpkQtgJs3Z",
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "print(\"\\n\\n\".join(initial_summary[:10]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "KlPC414VJs3Z"
   },
   "source": [
    "Aqui você contará o número de caracteres no resumo inicial para ver se eles são pequenos o suficiente para caber em um prompt."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "GtetmxSRJs3Z"
   },
   "outputs": [],
   "source": [
    "len(\"\\n\".join(initial_summary))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "TRAxL2PxJs3Z"
   },
   "source": [
    "Como você conseguiu inserir 30.000 caracteres em um prompt anteriormente, também pode inserir todo esse resumo com menos caracteres em um prompt. Você fará isso na próxima etapa."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "bdgZs93AJs3Z"
   },
   "source": [
    "#### Etapa de Reduce\n",
    "\n",
    "Aqui você criará uma função de redução que concatenará os resumos da etapa de resumo inicial (etapa Map) e usará o modelo de prompt final para resumir os resumos novamente."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "QS4caPjNJs3Z"
   },
   "outputs": [],
   "source": [
    "# define a função que cria o sumário de sumários\n",
    "def reduce(summary, prompt_template):\n",
    "\n",
    "    # concatena os sumários da etapa inicial\n",
    "    concat_summary = \"\\n\".join(initial_summary)\n",
    "\n",
    "    # cria o prompt para o modelo usando o texto concatenado e a template de prompt\n",
    "    prompt = prompt_template.format(text=concat_summary)\n",
    "\n",
    "    # gera o sumário utilizando o modelo e o prompt\n",
    "    summary = model_with_limit_and_backoff(prompt=prompt, max_output_tokens=1024).text\n",
    "\n",
    "    return summary"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "9OxwetDgKoUg"
   },
   "source": [
    "Você está pronto para prosseguir para a próxima etapa para combinar todo o resumo em um resumo ainda menor usando o modelo de prompt final e a função que você criou anteriormente."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "uvd7MUrSKfu-"
   },
   "outputs": [],
   "source": [
    "# Use a função `reduce` definida para resumir os resumos\n",
    "summary = reduce(initial_summary, final_prompt_template)\n",
    "\n",
    "print(summary)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "AjkbEdTYJs3Z"
   },
   "source": [
    "#### Recapitulando\n",
    "\n",
    "Você acabou de resumir todo o artigo em alguns marcadores usando o método MapReduce. Aqui estão os prós e contras de usar esse método:\n",
    "\n",
    "**Prós:**\n",
    "- Pode resumir um documento grande\n",
    "- Pode funcionar bem com processamento paralelo, pois os processos para resumir as páginas são independentes entre si\n",
    "\n",
    "**Contras:**\n",
    "- Múltiplas chamadas para o modelo são necessárias\n",
    "- Como as páginas são resumidas individualmente, o contexto entre as páginas pode ser perdido\n",
    "\n",
    "Na próxima seção, você tentará outro método que usa mais de um bloco (página) por prompt para resumir."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "rpQV6viOlUgH"
   },
   "source": [
    "## Método 3: MapReduce com overlapping chunks (ou partes sobrespostos)\n",
    "\n",
    "É semelhante ao MapReduce, mas com uma diferença fundamental: partes sobrepostas. Isso significa que algumas páginas serão resumidas juntas, em vez de cada página ser resumida separadamente. Isso ajuda a preservar mais contexto ou informações entre os blocos, o que pode melhorar a precisão dos resultados.\n",
    "\n",
    "É importante observar que a combinação de blocos às vezes pode exceder o limite de token imposto pelo modelo. Se isso ocorrer, você pode implementar o método de divisão de blocos ou resolver o problema de forma criativa (por exemplo, removendo alguns blocos iniciais)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "SiPq5CqJJs3c"
   },
   "source": [
    "#### Etapa de Map\n",
    "\n",
    "Nesta seção, você lerá o arquivo PDF novamente e usará o modelo para resumir <b>algumas páginas</b> usando o modelo de prompt inicial definido anteriormente."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ux6pPmPoJs3c"
   },
   "outputs": [],
   "source": [
    "# le o pdf e cria uma lista de páginas\n",
    "reader = PyPDF2.PdfReader(pdf_file)\n",
    "pages = reader.pages\n",
    "\n",
    "# cria uma lista pra armazenar o conteúdo extraído das páginas\n",
    "text_from_pages = []\n",
    "\n",
    "# iteração nas páginas pra gerar o sumário de cada página\n",
    "for page in tqdm(pages):\n",
    "\n",
    "    # extrai o texto da página e remove os espaços em branco\n",
    "    text = page.extract_text().strip()\n",
    "\n",
    "    # append do conteúdo extraído Append the extracted text to the list of extracted text\n",
    "    text_from_pages.append(text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ZD7HMdQgXuP0"
   },
   "source": [
    "Aqui você definirá o tamanho do bloco (número de páginas a serem combinadas neste exemplo) e resumirá os blocos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ZOA0Aq1nJs3c"
   },
   "outputs": [],
   "source": [
    "CHUNK_SIZE = 2  # número de páginas combinadas\n",
    "\n",
    "# le o pdf e cria a lista de páginas\n",
    "reader = PyPDF2.PdfReader(pdf_file)\n",
    "pages = reader.pages\n",
    "\n",
    "# cria a lista que armazenará os sumários\n",
    "initial_summary = []\n",
    "\n",
    "# iterage nas páginas e gera o sumário das páginas de acordo com o CHUNK_SIZE\n",
    "for i in tqdm(range(len(pages))):\n",
    "\n",
    "    # seleciona a lista de páginas e combina como um único chunk\n",
    "    pages_to_merge = [x for x in range(i, i + CHUNK_SIZE) if x < len(pages)]\n",
    "\n",
    "    extracted_texts = [text_from_pages[x] for x in pages_to_merge]\n",
    "\n",
    "    # concatena o sumário do chunk\n",
    "    text = \"\\n\".join(extracted_texts)\n",
    "\n",
    "    # cria o prompt para o modelo utilizando o texto concatenado e a template de prompt\n",
    "    prompt = initial_prompt_template.format(text=text)\n",
    "\n",
    "    # gera o sumário usando o modelo e o prompt\n",
    "    summary = model_with_limit_and_backoff(prompt=prompt, max_output_tokens=1024).text\n",
    "\n",
    "    # faz append do sumário na lista de sumários\n",
    "    initial_summary.append(summary)\n",
    "\n",
    "    # If the last page is reached, break the loop\n",
    "    if pages_to_merge[-1] == len(reader.pages):\n",
    "        break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "KVUVGBfbekfL"
   },
   "source": [
    "Dê uma olhada nos primeiros resumos da frase inicial do Map."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "uxgPKJ7BefyX",
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "print(\"\\n\\n\".join(initial_summary[:10]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "oL7aV6U2Js3d"
   },
   "source": [
    "#### Etapa de Reduce\n",
    "\n",
    "Você está pronto para prosseguir para a próxima etapa para combinar todo o resumo em um resumo ainda menor usando o modelo de prompt final e a função que você criou anteriormente."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "AxqSucUgJs3d"
   },
   "outputs": [],
   "source": [
    "# usa a função `reduce` para fazer o sumário dos sumários\n",
    "summary = reduce(initial_summary, final_prompt_template)\n",
    "\n",
    "print(summary)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "V6UpRIozJs3d"
   },
   "source": [
    "#### Recapitulando\n",
    "\n",
    "O modelo foi capaz de resumir todo o artigo em alguns pontos usando o método MapReduce com Overlapping Chunks. Aqui estão os prós e contras de usar esse método:\n",
    "\n",
    "**Prós:**\n",
    "- Pode resumir um documento grande\n",
    "- Como as páginas sequenciais são resumidas juntas, o contexto entre as páginas é preservado\n",
    "- Pode usar processamento paralelo, pois os resultados são independentes entre si\n",
    "\n",
    "**Contras:**\n",
    "- Múltiplas chamadas para o modelo são necessárias\n",
    "- Um pouco mais lento que o método MapReduce puro\n",
    "- Criar texto de entrada maior\n",
    "\n",
    "Na próxima seção, você tentará uma abordagem diferente que usa um resumo da página anterior em vez do texto inteiro."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "fFqa_qCmJs3d"
   },
   "source": [
    "## Método 4: MapReduce com resumo contínuo (refinamento)\n",
    "\n",
    "Em algumas ocasiões, combinar algumas páginas pode ser muito grande para resumir. Para resolver esse problema, agora você terá uma abordagem diferente que usa um resumo inicial da etapa anterior junto com a próxima página para resumir cada prompt. Isso ajuda a garantir que o resumo seja completo e preciso, pois leva em consideração o contexto da página anterior."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "zfK3SQMSJs3d"
   },
   "outputs": [],
   "source": [
    "initial_prompt_template = \"\"\"\n",
    "    Levando em consideração o contexto abaixo, delimitado por aspas invertidas triplas:\n",
    "\n",
    "    ```{context}```\n",
    "\n",
    "    Escreva um sumário conciso sobre o seguinte texto delimitado por aspas invertidas.\n",
    "\n",
    "    ```{text}```\n",
    "\n",
    "    SUMÁRIO CONCISO:\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "9sCN849gJs3d"
   },
   "outputs": [],
   "source": [
    "# le o pdf e cria a lista de páginas\n",
    "reader = PyPDF2.PdfReader(pdf_file)\n",
    "pages = reader.pages\n",
    "\n",
    "# cria a lista que armazenará os sumários\n",
    "initial_summary = []\n",
    "\n",
    "# # iterage nas páginas e gera o sumário das páginas\n",
    "for idx, page in enumerate(tqdm(pages)):\n",
    "\n",
    "    # extrai o texto da página e remove os espaços\n",
    "    text = page.extract_text().strip()\n",
    "\n",
    "    if idx == 0:  # se for a primeira página, não há contexto prévio\n",
    "        prompt = initial_prompt_template.format(context=\"\", text=text)\n",
    "\n",
    "    else:  # se não for a primeira página, o contexto prévio é o sumário da página anterior\n",
    "        prompt = initial_prompt_template.format(\n",
    "            context=initial_summary[idx - 1], text=text\n",
    "        )\n",
    "\n",
    "    # gera o sumário utilizando o modelo e a template de prompt\n",
    "    summary = model_with_limit_and_backoff(prompt=prompt, max_output_tokens=1024).text\n",
    "\n",
    "    # append do sumário na lista de sumários\n",
    "    initial_summary.append(summary)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "NJ3cOxWOJs3d"
   },
   "source": [
    "Aqui você listará algumas entradas da lista de resumo inicial."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "L5yOZikVJs3d",
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "print(\"\\n\\n\".join(initial_summary[:10]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "OYYZM4QOJs3d"
   },
   "source": [
    "Espera-se que haja algumas entradas duplicadas na lista, pois você está rolando no contexto das páginas anteriores para a próxima. Você pode facilmente remover essas duplicatas usando a função `set` do Python."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "9HczirNnJs3d"
   },
   "source": [
    "#### Etapa de Reduce\n",
    "Você está pronto para prosseguir para a próxima etapa para combinar todo o resumo em um resumo ainda menor usando o modelo de prompt final e a função que você criou anteriormente."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "I8Mg8MaaJs3d"
   },
   "outputs": [],
   "source": [
    "# usa a função `reduce` para fazer o sumário dos sumários\n",
    "initial_summary = set(initial_summary)  # set() para remover os itens duplicados\n",
    "summary = reduce(initial_summary, final_prompt_template)\n",
    "\n",
    "print(summary)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "_5wFY2SLJs3d"
   },
   "source": [
    "#### Recapitulando\n",
    "\n",
    "O modelo foi capaz de resumir todo o artigo em alguns pontos usando o método MapReduce with Rolling Summary. Aqui estão os prós e contras de usar esse método:\n",
    "\n",
    "**Prós:**\n",
    "- Pode resumir um documento grande\n",
    "- Como as páginas sequenciais são resumidas usando o contexto das páginas anteriores, o contexto entre as páginas é preservado\n",
    "\n",
    "**Contras:**\n",
    "- Múltiplas chamadas para o modelo são necessárias\n",
    "- Não pode funcionar bem com processamento paralelo, pois os processos para resumir as páginas dependem uns dos outros"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "LNyorWQgJs3d"
   },
   "source": [
    "## Conclusão\n",
    "\n",
    "Você resumiu com sucesso um documento longo, mesmo que inicialmente fosse impossível devido a um limite de prompt de entrada. Você também aprendeu vários métodos para resumir documentos longos, junto com suas vantagens e desvantagens.\n",
    "\n",
    "Resumir um documento longo pode ser um desafio. Exige que você identifique os pontos principais do documento, sintetize as informações e apresente-as de forma concisa e coerente. Isso pode ser especialmente difícil se o documento for complexo ou técnico. Além disso, resumir um documento longo pode ser demorado, pois você precisa ler e analisar cuidadosamente o texto para garantir que o resumo seja preciso e completo.\n",
    "\n",
    "Embora esses métodos permitam interagir com LLMs e resumir documentos longos de maneira flexível, às vezes você pode querer acelerar o processo usando bootstrapping ou métodos pré-construídos. É aqui que entram as bibliotecas como LangChain. Você pode ler mais sobre o suporte LangChain na Vertex AI [aqui](https://python.langchain.com/en/latest/modules/models/llms/integrations/google_vertex_ai_palm.html)."
   ]
  }
 ],
 "metadata": {
  "colab": {
   "name": "summarization_large_documents.ipynb",
   "toc_visible": true
  },
  "environment": {
   "kernel": "python3",
   "name": "tf2-gpu.2-11.m109",
   "type": "gcloud",
   "uri": "gcr.io/deeplearning-platform-release/tf2-gpu.2-11:m109"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
